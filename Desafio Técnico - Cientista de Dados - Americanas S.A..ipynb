{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3156b158",
   "metadata": {},
   "source": [
    "# <center> Desafio Técnico - Cientista de Dados - Americanas S.A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a240441c",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> O objetivo deste trabalho é apresentar a minha solução para o Desafio Técnico do processo seletivo para a posição de Cientista de Dados Júnior na Americanas S.A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d2338",
   "metadata": {},
   "source": [
    "Este documento está dividido em quatro partes : **Análise Exploratória dos Dados** , **Preparação dos Dados** , **Modelagem** e **Avaliação da Performance do Modelo**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d15949c",
   "metadata": {},
   "source": [
    "Em um notebook separado está localizada a parte final do desafio, ou seja, a **Entrega do Modelo**. Esse notebook pode ser encontrado no repositório criado para hospedar minha solução cujo endereço é https://github.com/LucasPorto2/Desafio-Tecnico-Americanas-S.A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e216cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando algumas bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier , GradientBoostingClassifier , VotingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score , GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ce7b5",
   "metadata": {},
   "source": [
    "## <center>  1. Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a1773",
   "metadata": {},
   "source": [
    "### 1.1 Leitura do Arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa71099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o conjunto de dados e transformando o mesmo em um dataframe\n",
    "\n",
    "df = pd.read_parquet('dataset_cdjr.parquet.gzip' , engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4609e1",
   "metadata": {},
   "source": [
    "### 1.2 Observações Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1b2de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a dimensão do dataset\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765354a2",
   "metadata": {},
   "source": [
    "De fato existem 466 entradas e 17 colunas (16 features e uma variável alvo) conforme informado !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9367ce6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2</td>\n",
       "      <td>662.28</td>\n",
       "      <td>39.10</td>\n",
       "      <td>-188.55</td>\n",
       "      <td>0.246978</td>\n",
       "      <td>761</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>3.523703</td>\n",
       "      <td>167326</td>\n",
       "      <td>33441.06</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>26.850</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>94.611429</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>149.55</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79</td>\n",
       "      <td>78.93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>346.08</td>\n",
       "      <td>30.41</td>\n",
       "      <td>-102.10</td>\n",
       "      <td>2.430952</td>\n",
       "      <td>42</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>3.389618</td>\n",
       "      <td>9907</td>\n",
       "      <td>18858.77</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>25.525</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>86.520000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.84</td>\n",
       "      <td>-56.16</td>\n",
       "      <td>0.150968</td>\n",
       "      <td>372</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63544</td>\n",
       "      <td>1164.11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>87.56</td>\n",
       "      <td>-3.05</td>\n",
       "      <td>-94.50</td>\n",
       "      <td>0.412664</td>\n",
       "      <td>229</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.926561</td>\n",
       "      <td>50089</td>\n",
       "      <td>1786.26</td>\n",
       "      <td>0.049019</td>\n",
       "      <td>94.500</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>87.560000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "337     200.0         2    662.28     39.10   -188.55  0.246978       761   \n",
       "266     150.0         2      0.00    149.55     -0.45  0.150000         3   \n",
       "236      50.0         1    346.08     30.41   -102.10  2.430952        42   \n",
       "274     100.0         2      0.00     43.84    -56.16  0.150968       372   \n",
       "208      50.0         1     87.56     -3.05    -94.50  0.412664       229   \n",
       "\n",
       "     feature7  feature8  feature9  feature10  feature11  feature12  feature13  \\\n",
       "337  0.004548  3.523703    167326   33441.06   0.019804     26.850   0.009198   \n",
       "266  0.037975  0.000000        79      78.93   0.000000      0.000   0.000000   \n",
       "236  0.004239  3.389618      9907   18858.77   0.018351     25.525   0.095238   \n",
       "274  0.005854  0.000000     63544    1164.11   0.000000      0.000   0.000000   \n",
       "208  0.004572  0.926561     50089    1786.26   0.049019     94.500   0.004367   \n",
       "\n",
       "     feature14  feature15  target  \n",
       "337  94.611429          7       0  \n",
       "266   0.000000          0       1  \n",
       "236  86.520000          4       0  \n",
       "274   0.000000          0       1  \n",
       "208  87.560000          1       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observando as 5 primeiras linhas do nosso dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3da42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature0     0\n",
       "feature1     0\n",
       "feature2     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "target       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando o número de valores ausentes por coluna \n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b136b",
   "metadata": {},
   "source": [
    "Que ótimo ! Não possuimos valores faltantes em nosso conjunto de dados logo não precisamos nos preocupar em lidar com valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc60c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>4.660000e+02</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>466.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>438.743562</td>\n",
       "      <td>4.847639</td>\n",
       "      <td>1244.322468</td>\n",
       "      <td>44.600880</td>\n",
       "      <td>-434.299893</td>\n",
       "      <td>0.473991</td>\n",
       "      <td>979.070815</td>\n",
       "      <td>0.113885</td>\n",
       "      <td>3.857010</td>\n",
       "      <td>2.164378e+05</td>\n",
       "      <td>6930.456438</td>\n",
       "      <td>0.437333</td>\n",
       "      <td>61.886190</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>87.713360</td>\n",
       "      <td>10.313305</td>\n",
       "      <td>0.557940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>984.593065</td>\n",
       "      <td>6.836679</td>\n",
       "      <td>3558.699033</td>\n",
       "      <td>122.093515</td>\n",
       "      <td>975.555198</td>\n",
       "      <td>0.452261</td>\n",
       "      <td>1460.738442</td>\n",
       "      <td>1.873746</td>\n",
       "      <td>15.609132</td>\n",
       "      <td>3.508622e+05</td>\n",
       "      <td>17581.800818</td>\n",
       "      <td>3.442094</td>\n",
       "      <td>142.521523</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>145.426437</td>\n",
       "      <td>33.625204</td>\n",
       "      <td>0.497165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-645.870000</td>\n",
       "      <td>-15506.350000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-492.035000</td>\n",
       "      <td>0.173669</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.113100e+04</td>\n",
       "      <td>383.687500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>169.830000</td>\n",
       "      <td>18.360000</td>\n",
       "      <td>-154.525000</td>\n",
       "      <td>0.303854</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.937082</td>\n",
       "      <td>8.532850e+04</td>\n",
       "      <td>1410.855000</td>\n",
       "      <td>0.082515</td>\n",
       "      <td>19.692568</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>72.524286</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1017.375000</td>\n",
       "      <td>44.630000</td>\n",
       "      <td>-50.180000</td>\n",
       "      <td>0.569848</td>\n",
       "      <td>1238.750000</td>\n",
       "      <td>0.009699</td>\n",
       "      <td>2.815824</td>\n",
       "      <td>2.645035e+05</td>\n",
       "      <td>5212.977500</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>65.498098</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>127.301505</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15400.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>40291.240000</td>\n",
       "      <td>1521.900000</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>11731.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>281.666667</td>\n",
       "      <td>3.366472e+06</td>\n",
       "      <td>237182.780000</td>\n",
       "      <td>73.080634</td>\n",
       "      <td>2232.100000</td>\n",
       "      <td>0.204611</td>\n",
       "      <td>2154.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature0    feature1      feature2     feature3      feature4  \\\n",
       "count    466.000000  466.000000    466.000000   466.000000    466.000000   \n",
       "mean     438.743562    4.847639   1244.322468    44.600880   -434.299893   \n",
       "std      984.593065    6.836679   3558.699033   122.093515    975.555198   \n",
       "min        0.000000    0.000000      0.000000  -645.870000 -15506.350000   \n",
       "25%       50.000000    1.000000      0.000000    -0.400000   -492.035000   \n",
       "50%      150.000000    2.000000    169.830000    18.360000   -154.525000   \n",
       "75%      500.000000    6.000000   1017.375000    44.630000    -50.180000   \n",
       "max    15400.000000   31.000000  40291.240000  1521.900000     -0.260000   \n",
       "\n",
       "         feature5      feature6    feature7    feature8      feature9  \\\n",
       "count  466.000000    466.000000  466.000000  466.000000  4.660000e+02   \n",
       "mean     0.473991    979.070815    0.113885    3.857010  2.164378e+05   \n",
       "std      0.452261   1460.738442    1.873746   15.609132  3.508622e+05   \n",
       "min      0.150000      1.000000    0.000663    0.000000  1.000000e+00   \n",
       "25%      0.173669    133.500000    0.003318    0.000000  2.113100e+04   \n",
       "50%      0.303854    420.000000    0.005127    0.937082  8.532850e+04   \n",
       "75%      0.569848   1238.750000    0.009699    2.815824  2.645035e+05   \n",
       "max      3.150000  11731.000000   40.000000  281.666667  3.366472e+06   \n",
       "\n",
       "           feature10   feature11    feature12   feature13    feature14  \\\n",
       "count     466.000000  466.000000   466.000000  466.000000   466.000000   \n",
       "mean     6930.456438    0.437333    61.886190    0.008634    87.713360   \n",
       "std     17581.800818    3.442094   142.521523    0.017866   145.426437   \n",
       "min         0.000000    0.000000     0.000000    0.000000     0.000000   \n",
       "25%       383.687500    0.000000     0.000000    0.000000     0.000000   \n",
       "50%      1410.855000    0.082515    19.692568    0.003207    72.524286   \n",
       "75%      5212.977500    0.311311    65.498098    0.009515   127.301505   \n",
       "max    237182.780000   73.080634  2232.100000    0.204611  2154.000000   \n",
       "\n",
       "        feature15      target  \n",
       "count  466.000000  466.000000  \n",
       "mean    10.313305    0.557940  \n",
       "std     33.625204    0.497165  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      8.000000    1.000000  \n",
       "max    541.000000    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo algumas estatísticas básicas \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17191cd",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Com apenas algumas estatísticas básicas percebemos que a maioria das features possuí alta variância. Por exemplo a feature9 assume valores entre 1 e 3366472. Isso já é um forte indicativo que devemos nos preocupar com o dimensionamento dos dados, porém isso será melhor abordado na seção Feature Scaling dentro do tópico Preparação dos Dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b4b62ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature0     float64\n",
       "feature1       int64\n",
       "feature2     float64\n",
       "feature3     float64\n",
       "feature4     float64\n",
       "feature5     float64\n",
       "feature6       int64\n",
       "feature7     float64\n",
       "feature8     float64\n",
       "feature9       int64\n",
       "feature10    float64\n",
       "feature11    float64\n",
       "feature12    float64\n",
       "feature13    float64\n",
       "feature14    float64\n",
       "feature15      int64\n",
       "target         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observando os tipos de dado em nosso dataset\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27af1f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    260\n",
       "0    206\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando como de fato todas as entradas da variável target são 0s ou 1s\n",
    "\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaa61a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.793991416309005"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % de exemplos onde target = 1\n",
    "\n",
    "(260/466)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "034d7ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.20600858369099"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % de exemplos onde target = 0\n",
    "\n",
    "(206/466)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7798659",
   "metadata": {},
   "source": [
    "## <center> 2. Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6d3b7",
   "metadata": {},
   "source": [
    "### 2.1 Separando o dataset em Features e Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f765191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a matriz de features\n",
    "\n",
    "X = np.array(df.drop('target' , axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaf825a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o array target\n",
    "\n",
    "target = np.array(df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c1f19",
   "metadata": {},
   "source": [
    "### 2.2 Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46f9ed",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> O dimensionamento dos dados ou Feature Scaling é algo sempre muito importante para levarmos em conta em um projeto de Ciência de Dados. Quando certas variáveis assumem valores em um intervalo muito grande isso pode acabar impactando o treinamento dos modelos uma vez que muitos algoritmos de Machine Learning calculam distâncias entre pontos das amostras e se os dados estiverem em escalas muito diferentes podemos ter distâncias muito elevadas o que acaba por gerar problemas em nossas previsões."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192721d",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Para realizar essa etapa vamos utilizar o StandardScaler do Scikit-Learn para obrigar nossas variáveis a terem média 0 e desvio-padrão 1 (aproximar uma distribuição normal padrão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "736a178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o método\n",
    "\n",
    "SS = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5790b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "X = SS.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6ee7ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24274002, -0.41697144, -0.16373062, ...,  0.03161502,\n",
       "         0.04748436, -0.09864224],\n",
       "       [-0.29357699, -0.41697144, -0.35003233, ..., -0.48378748,\n",
       "        -0.6037941 , -0.30704315],\n",
       "       [-0.39525095, -0.56339849, -0.2526788 , ...,  4.85255679,\n",
       "        -0.00821475, -0.18795692],\n",
       "       ...,\n",
       "       [-0.03939211, -0.12411735, -0.04057873, ...,  0.18553215,\n",
       "         0.47800197, -0.09864224],\n",
       "       [-0.29357699, -0.56339849, -0.35003233, ..., -0.48378748,\n",
       "        -0.6037941 , -0.30704315],\n",
       "       [-0.39525095, -0.56339849, -0.35003233, ..., -0.48378748,\n",
       "        -0.6037941 , -0.30704315]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz transformada\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32aebebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testando se de fato a primeira coluna possui média 0 e desvio-padrão 1\n",
    "\n",
    "np.mean(X[: , 0]) , np.std(X[: , 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9827f",
   "metadata": {},
   "source": [
    "Tudo correto !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a1e9e",
   "metadata": {},
   "source": [
    "## <center> 3. Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3ad9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos a serem testados\n",
    "\n",
    "modelos = [LogisticRegression() , KNeighborsClassifier() , SVC() , DecisionTreeClassifier() ,\n",
    "           RandomForestClassifier() , AdaBoostClassifier() , GradientBoostingClassifier() ,\n",
    "           XGBClassifier(use_label_encoder = False) , LGBMClassifier(), CatBoostClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a1e6c",
   "metadata": {},
   "source": [
    "Vamos inicialmente medir a acurácia de cada modelo no conjunto de treinamento, ou seja, vamos treinar o modelo no dataset inteiro (466 amostras) e vamos medir a acurácia que o modelo obtém quando fazemos previsões no próprio conjunto de treino. Para isso criaremos uma lista acc_treino inicialmente vazia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b52a2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_treino = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41a574b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:38:14] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.007436\n",
      "0:\tlearn: 0.6919471\ttotal: 194ms\tremaining: 3m 13s\n",
      "1:\tlearn: 0.6905011\ttotal: 237ms\tremaining: 1m 58s\n",
      "2:\tlearn: 0.6893491\ttotal: 282ms\tremaining: 1m 33s\n",
      "3:\tlearn: 0.6879204\ttotal: 315ms\tremaining: 1m 18s\n",
      "4:\tlearn: 0.6865646\ttotal: 340ms\tremaining: 1m 7s\n",
      "5:\tlearn: 0.6848357\ttotal: 372ms\tremaining: 1m 1s\n",
      "6:\tlearn: 0.6829308\ttotal: 414ms\tremaining: 58.7s\n",
      "7:\tlearn: 0.6821643\ttotal: 465ms\tremaining: 57.6s\n",
      "8:\tlearn: 0.6806840\ttotal: 501ms\tremaining: 55.2s\n",
      "9:\tlearn: 0.6792351\ttotal: 540ms\tremaining: 53.4s\n",
      "10:\tlearn: 0.6780155\ttotal: 576ms\tremaining: 51.8s\n",
      "11:\tlearn: 0.6767936\ttotal: 606ms\tremaining: 49.9s\n",
      "12:\tlearn: 0.6754268\ttotal: 626ms\tremaining: 47.6s\n",
      "13:\tlearn: 0.6738677\ttotal: 652ms\tremaining: 45.9s\n",
      "14:\tlearn: 0.6727786\ttotal: 668ms\tremaining: 43.9s\n",
      "15:\tlearn: 0.6717556\ttotal: 685ms\tremaining: 42.1s\n",
      "16:\tlearn: 0.6704102\ttotal: 706ms\tremaining: 40.9s\n",
      "17:\tlearn: 0.6691783\ttotal: 727ms\tremaining: 39.7s\n",
      "18:\tlearn: 0.6681920\ttotal: 768ms\tremaining: 39.6s\n",
      "19:\tlearn: 0.6672162\ttotal: 809ms\tremaining: 39.7s\n",
      "20:\tlearn: 0.6656892\ttotal: 833ms\tremaining: 38.8s\n",
      "21:\tlearn: 0.6643008\ttotal: 865ms\tremaining: 38.4s\n",
      "22:\tlearn: 0.6627164\ttotal: 883ms\tremaining: 37.5s\n",
      "23:\tlearn: 0.6614928\ttotal: 904ms\tremaining: 36.8s\n",
      "24:\tlearn: 0.6601596\ttotal: 919ms\tremaining: 35.8s\n",
      "25:\tlearn: 0.6588812\ttotal: 942ms\tremaining: 35.3s\n",
      "26:\tlearn: 0.6574345\ttotal: 969ms\tremaining: 34.9s\n",
      "27:\tlearn: 0.6560171\ttotal: 992ms\tremaining: 34.4s\n",
      "28:\tlearn: 0.6543601\ttotal: 1.04s\tremaining: 34.7s\n",
      "29:\tlearn: 0.6528757\ttotal: 1.06s\tremaining: 34.4s\n",
      "30:\tlearn: 0.6512690\ttotal: 1.08s\tremaining: 33.7s\n",
      "31:\tlearn: 0.6501500\ttotal: 1.09s\tremaining: 33.1s\n",
      "32:\tlearn: 0.6490143\ttotal: 1.11s\tremaining: 32.5s\n",
      "33:\tlearn: 0.6478337\ttotal: 1.13s\tremaining: 32.1s\n",
      "34:\tlearn: 0.6470805\ttotal: 1.15s\tremaining: 31.6s\n",
      "35:\tlearn: 0.6460568\ttotal: 1.18s\tremaining: 31.5s\n",
      "36:\tlearn: 0.6450372\ttotal: 1.2s\tremaining: 31.2s\n",
      "37:\tlearn: 0.6438402\ttotal: 1.23s\tremaining: 31.1s\n",
      "38:\tlearn: 0.6427804\ttotal: 1.25s\tremaining: 30.9s\n",
      "39:\tlearn: 0.6419785\ttotal: 1.28s\tremaining: 30.8s\n",
      "40:\tlearn: 0.6407686\ttotal: 1.3s\tremaining: 30.5s\n",
      "41:\tlearn: 0.6397002\ttotal: 1.32s\tremaining: 30.1s\n",
      "42:\tlearn: 0.6390045\ttotal: 1.33s\tremaining: 29.7s\n",
      "43:\tlearn: 0.6379206\ttotal: 1.35s\tremaining: 29.3s\n",
      "44:\tlearn: 0.6365839\ttotal: 1.37s\tremaining: 29s\n",
      "45:\tlearn: 0.6357352\ttotal: 1.38s\tremaining: 28.7s\n",
      "46:\tlearn: 0.6348650\ttotal: 1.4s\tremaining: 28.5s\n",
      "47:\tlearn: 0.6339045\ttotal: 1.44s\tremaining: 28.5s\n",
      "48:\tlearn: 0.6330590\ttotal: 1.46s\tremaining: 28.2s\n",
      "49:\tlearn: 0.6320177\ttotal: 1.49s\tremaining: 28.4s\n",
      "50:\tlearn: 0.6310709\ttotal: 1.51s\tremaining: 28.2s\n",
      "51:\tlearn: 0.6304332\ttotal: 1.53s\tremaining: 27.9s\n",
      "52:\tlearn: 0.6297272\ttotal: 1.55s\tremaining: 27.6s\n",
      "53:\tlearn: 0.6286267\ttotal: 1.56s\tremaining: 27.3s\n",
      "54:\tlearn: 0.6278178\ttotal: 1.57s\tremaining: 27.1s\n",
      "55:\tlearn: 0.6268216\ttotal: 1.59s\tremaining: 26.9s\n",
      "56:\tlearn: 0.6256726\ttotal: 1.61s\tremaining: 26.7s\n",
      "57:\tlearn: 0.6250040\ttotal: 1.65s\tremaining: 26.8s\n",
      "58:\tlearn: 0.6238443\ttotal: 1.7s\tremaining: 27.1s\n",
      "59:\tlearn: 0.6225772\ttotal: 1.73s\tremaining: 27.2s\n",
      "60:\tlearn: 0.6218084\ttotal: 1.77s\tremaining: 27.2s\n",
      "61:\tlearn: 0.6210526\ttotal: 1.81s\tremaining: 27.3s\n",
      "62:\tlearn: 0.6201532\ttotal: 1.82s\tremaining: 27.1s\n",
      "63:\tlearn: 0.6194436\ttotal: 1.84s\tremaining: 27s\n",
      "64:\tlearn: 0.6186742\ttotal: 1.87s\tremaining: 26.9s\n",
      "65:\tlearn: 0.6178906\ttotal: 1.89s\tremaining: 26.7s\n",
      "66:\tlearn: 0.6166830\ttotal: 1.92s\tremaining: 26.8s\n",
      "67:\tlearn: 0.6155472\ttotal: 1.96s\tremaining: 26.9s\n",
      "68:\tlearn: 0.6149631\ttotal: 1.99s\tremaining: 26.9s\n",
      "69:\tlearn: 0.6142552\ttotal: 2.01s\tremaining: 26.8s\n",
      "70:\tlearn: 0.6134232\ttotal: 2.03s\tremaining: 26.6s\n",
      "71:\tlearn: 0.6126882\ttotal: 2.06s\tremaining: 26.5s\n",
      "72:\tlearn: 0.6115215\ttotal: 2.08s\tremaining: 26.4s\n",
      "73:\tlearn: 0.6105875\ttotal: 2.1s\tremaining: 26.3s\n",
      "74:\tlearn: 0.6098356\ttotal: 2.14s\tremaining: 26.4s\n",
      "75:\tlearn: 0.6089752\ttotal: 2.17s\tremaining: 26.4s\n",
      "76:\tlearn: 0.6081641\ttotal: 2.2s\tremaining: 26.4s\n",
      "77:\tlearn: 0.6076226\ttotal: 2.22s\tremaining: 26.3s\n",
      "78:\tlearn: 0.6067255\ttotal: 2.24s\tremaining: 26.2s\n",
      "79:\tlearn: 0.6055695\ttotal: 2.26s\tremaining: 26s\n",
      "80:\tlearn: 0.6045712\ttotal: 2.29s\tremaining: 25.9s\n",
      "81:\tlearn: 0.6035378\ttotal: 2.32s\tremaining: 25.9s\n",
      "82:\tlearn: 0.6028523\ttotal: 2.35s\tremaining: 25.9s\n",
      "83:\tlearn: 0.6019461\ttotal: 2.37s\tremaining: 25.9s\n",
      "84:\tlearn: 0.6010581\ttotal: 2.41s\tremaining: 25.9s\n",
      "85:\tlearn: 0.6002278\ttotal: 2.42s\tremaining: 25.8s\n",
      "86:\tlearn: 0.5997521\ttotal: 2.44s\tremaining: 25.6s\n",
      "87:\tlearn: 0.5991711\ttotal: 2.46s\tremaining: 25.5s\n",
      "88:\tlearn: 0.5981539\ttotal: 2.48s\tremaining: 25.4s\n",
      "89:\tlearn: 0.5973133\ttotal: 2.5s\tremaining: 25.3s\n",
      "90:\tlearn: 0.5966100\ttotal: 2.52s\tremaining: 25.2s\n",
      "91:\tlearn: 0.5958456\ttotal: 2.56s\tremaining: 25.3s\n",
      "92:\tlearn: 0.5950584\ttotal: 2.59s\tremaining: 25.3s\n",
      "93:\tlearn: 0.5941655\ttotal: 2.62s\tremaining: 25.3s\n",
      "94:\tlearn: 0.5936153\ttotal: 2.64s\tremaining: 25.2s\n",
      "95:\tlearn: 0.5926939\ttotal: 2.66s\tremaining: 25s\n",
      "96:\tlearn: 0.5920615\ttotal: 2.67s\tremaining: 24.9s\n",
      "97:\tlearn: 0.5909861\ttotal: 2.7s\tremaining: 24.8s\n",
      "98:\tlearn: 0.5900392\ttotal: 2.72s\tremaining: 24.7s\n",
      "99:\tlearn: 0.5892030\ttotal: 2.74s\tremaining: 24.7s\n",
      "100:\tlearn: 0.5884844\ttotal: 2.79s\tremaining: 24.8s\n",
      "101:\tlearn: 0.5877958\ttotal: 2.81s\tremaining: 24.8s\n",
      "102:\tlearn: 0.5871537\ttotal: 2.84s\tremaining: 24.7s\n",
      "103:\tlearn: 0.5864896\ttotal: 2.85s\tremaining: 24.6s\n",
      "104:\tlearn: 0.5858454\ttotal: 2.87s\tremaining: 24.5s\n",
      "105:\tlearn: 0.5847222\ttotal: 2.9s\tremaining: 24.5s\n",
      "106:\tlearn: 0.5840053\ttotal: 2.94s\tremaining: 24.6s\n",
      "107:\tlearn: 0.5831869\ttotal: 2.97s\tremaining: 24.6s\n",
      "108:\tlearn: 0.5825137\ttotal: 3s\tremaining: 24.5s\n",
      "109:\tlearn: 0.5817272\ttotal: 3.01s\tremaining: 24.4s\n",
      "110:\tlearn: 0.5808605\ttotal: 3.03s\tremaining: 24.3s\n",
      "111:\tlearn: 0.5804056\ttotal: 3.05s\tremaining: 24.2s\n",
      "112:\tlearn: 0.5798313\ttotal: 3.07s\tremaining: 24.1s\n",
      "113:\tlearn: 0.5791369\ttotal: 3.09s\tremaining: 24s\n",
      "114:\tlearn: 0.5781655\ttotal: 3.11s\tremaining: 23.9s\n",
      "115:\tlearn: 0.5776568\ttotal: 3.12s\tremaining: 23.8s\n",
      "116:\tlearn: 0.5767630\ttotal: 3.14s\tremaining: 23.7s\n",
      "117:\tlearn: 0.5760284\ttotal: 3.16s\tremaining: 23.6s\n",
      "118:\tlearn: 0.5750221\ttotal: 3.19s\tremaining: 23.6s\n",
      "119:\tlearn: 0.5745726\ttotal: 3.21s\tremaining: 23.6s\n",
      "120:\tlearn: 0.5738852\ttotal: 3.24s\tremaining: 23.5s\n",
      "121:\tlearn: 0.5732688\ttotal: 3.26s\tremaining: 23.5s\n",
      "122:\tlearn: 0.5727738\ttotal: 3.28s\tremaining: 23.4s\n",
      "123:\tlearn: 0.5721509\ttotal: 3.31s\tremaining: 23.4s\n",
      "124:\tlearn: 0.5712863\ttotal: 3.34s\tremaining: 23.4s\n",
      "125:\tlearn: 0.5704880\ttotal: 3.38s\tremaining: 23.4s\n",
      "126:\tlearn: 0.5700177\ttotal: 3.4s\tremaining: 23.3s\n",
      "127:\tlearn: 0.5692618\ttotal: 3.42s\tremaining: 23.3s\n",
      "128:\tlearn: 0.5686220\ttotal: 3.46s\tremaining: 23.3s\n",
      "129:\tlearn: 0.5679896\ttotal: 3.48s\tremaining: 23.3s\n",
      "130:\tlearn: 0.5672440\ttotal: 3.5s\tremaining: 23.2s\n",
      "131:\tlearn: 0.5665840\ttotal: 3.53s\tremaining: 23.2s\n",
      "132:\tlearn: 0.5659722\ttotal: 3.56s\tremaining: 23.2s\n",
      "133:\tlearn: 0.5652385\ttotal: 3.58s\tremaining: 23.1s\n",
      "134:\tlearn: 0.5645377\ttotal: 3.59s\tremaining: 23s\n",
      "135:\tlearn: 0.5641318\ttotal: 3.62s\tremaining: 23s\n",
      "136:\tlearn: 0.5636069\ttotal: 3.65s\tremaining: 23s\n",
      "137:\tlearn: 0.5630715\ttotal: 3.67s\tremaining: 22.9s\n",
      "138:\tlearn: 0.5624537\ttotal: 3.69s\tremaining: 22.8s\n",
      "139:\tlearn: 0.5617552\ttotal: 3.71s\tremaining: 22.8s\n",
      "140:\tlearn: 0.5609588\ttotal: 3.75s\tremaining: 22.8s\n",
      "141:\tlearn: 0.5603936\ttotal: 3.76s\tremaining: 22.7s\n",
      "142:\tlearn: 0.5596560\ttotal: 3.79s\tremaining: 22.7s\n",
      "143:\tlearn: 0.5590244\ttotal: 3.82s\tremaining: 22.7s\n",
      "144:\tlearn: 0.5580234\ttotal: 3.86s\tremaining: 22.7s\n",
      "145:\tlearn: 0.5574422\ttotal: 3.88s\tremaining: 22.7s\n",
      "146:\tlearn: 0.5568903\ttotal: 3.89s\tremaining: 22.6s\n",
      "147:\tlearn: 0.5560586\ttotal: 3.92s\tremaining: 22.6s\n",
      "148:\tlearn: 0.5551848\ttotal: 3.94s\tremaining: 22.5s\n",
      "149:\tlearn: 0.5545364\ttotal: 3.97s\tremaining: 22.5s\n",
      "150:\tlearn: 0.5540260\ttotal: 4s\tremaining: 22.5s\n",
      "151:\tlearn: 0.5534995\ttotal: 4.04s\tremaining: 22.5s\n",
      "152:\tlearn: 0.5528430\ttotal: 4.06s\tremaining: 22.5s\n",
      "153:\tlearn: 0.5520784\ttotal: 4.08s\tremaining: 22.4s\n",
      "154:\tlearn: 0.5515974\ttotal: 4.11s\tremaining: 22.4s\n",
      "155:\tlearn: 0.5509164\ttotal: 4.13s\tremaining: 22.4s\n",
      "156:\tlearn: 0.5502416\ttotal: 4.16s\tremaining: 22.3s\n",
      "157:\tlearn: 0.5497927\ttotal: 4.19s\tremaining: 22.3s\n",
      "158:\tlearn: 0.5491322\ttotal: 4.23s\tremaining: 22.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159:\tlearn: 0.5483776\ttotal: 4.26s\tremaining: 22.4s\n",
      "160:\tlearn: 0.5476587\ttotal: 4.28s\tremaining: 22.3s\n",
      "161:\tlearn: 0.5469019\ttotal: 4.3s\tremaining: 22.2s\n",
      "162:\tlearn: 0.5464025\ttotal: 4.32s\tremaining: 22.2s\n",
      "163:\tlearn: 0.5459364\ttotal: 4.35s\tremaining: 22.2s\n",
      "164:\tlearn: 0.5454833\ttotal: 4.38s\tremaining: 22.2s\n",
      "165:\tlearn: 0.5450015\ttotal: 4.42s\tremaining: 22.2s\n",
      "166:\tlearn: 0.5443010\ttotal: 4.46s\tremaining: 22.2s\n",
      "167:\tlearn: 0.5440958\ttotal: 4.49s\tremaining: 22.2s\n",
      "168:\tlearn: 0.5437624\ttotal: 4.51s\tremaining: 22.2s\n",
      "169:\tlearn: 0.5433421\ttotal: 4.53s\tremaining: 22.1s\n",
      "170:\tlearn: 0.5428974\ttotal: 4.54s\tremaining: 22s\n",
      "171:\tlearn: 0.5424637\ttotal: 4.57s\tremaining: 22s\n",
      "172:\tlearn: 0.5419747\ttotal: 4.6s\tremaining: 22s\n",
      "173:\tlearn: 0.5412840\ttotal: 4.63s\tremaining: 22s\n",
      "174:\tlearn: 0.5408359\ttotal: 4.67s\tremaining: 22s\n",
      "175:\tlearn: 0.5402849\ttotal: 4.69s\tremaining: 22s\n",
      "176:\tlearn: 0.5398002\ttotal: 4.71s\tremaining: 21.9s\n",
      "177:\tlearn: 0.5391779\ttotal: 4.73s\tremaining: 21.8s\n",
      "178:\tlearn: 0.5386287\ttotal: 4.75s\tremaining: 21.8s\n",
      "179:\tlearn: 0.5379591\ttotal: 4.78s\tremaining: 21.8s\n",
      "180:\tlearn: 0.5376224\ttotal: 4.81s\tremaining: 21.8s\n",
      "181:\tlearn: 0.5372769\ttotal: 4.84s\tremaining: 21.8s\n",
      "182:\tlearn: 0.5367851\ttotal: 4.88s\tremaining: 21.8s\n",
      "183:\tlearn: 0.5361926\ttotal: 4.9s\tremaining: 21.7s\n",
      "184:\tlearn: 0.5355998\ttotal: 4.92s\tremaining: 21.7s\n",
      "185:\tlearn: 0.5350057\ttotal: 4.94s\tremaining: 21.6s\n",
      "186:\tlearn: 0.5342913\ttotal: 4.96s\tremaining: 21.6s\n",
      "187:\tlearn: 0.5333902\ttotal: 4.98s\tremaining: 21.5s\n",
      "188:\tlearn: 0.5327217\ttotal: 5.01s\tremaining: 21.5s\n",
      "189:\tlearn: 0.5320791\ttotal: 5.04s\tremaining: 21.5s\n",
      "190:\tlearn: 0.5316182\ttotal: 5.07s\tremaining: 21.5s\n",
      "191:\tlearn: 0.5311258\ttotal: 5.1s\tremaining: 21.5s\n",
      "192:\tlearn: 0.5306575\ttotal: 5.12s\tremaining: 21.4s\n",
      "193:\tlearn: 0.5302988\ttotal: 5.14s\tremaining: 21.3s\n",
      "194:\tlearn: 0.5298714\ttotal: 5.15s\tremaining: 21.3s\n",
      "195:\tlearn: 0.5292416\ttotal: 5.18s\tremaining: 21.2s\n",
      "196:\tlearn: 0.5287700\ttotal: 5.2s\tremaining: 21.2s\n",
      "197:\tlearn: 0.5282370\ttotal: 5.24s\tremaining: 21.2s\n",
      "198:\tlearn: 0.5276693\ttotal: 5.27s\tremaining: 21.2s\n",
      "199:\tlearn: 0.5270455\ttotal: 5.3s\tremaining: 21.2s\n",
      "200:\tlearn: 0.5266179\ttotal: 5.32s\tremaining: 21.1s\n",
      "201:\tlearn: 0.5261837\ttotal: 5.34s\tremaining: 21.1s\n",
      "202:\tlearn: 0.5256257\ttotal: 5.35s\tremaining: 21s\n",
      "203:\tlearn: 0.5252207\ttotal: 5.37s\tremaining: 20.9s\n",
      "204:\tlearn: 0.5248962\ttotal: 5.39s\tremaining: 20.9s\n",
      "205:\tlearn: 0.5246137\ttotal: 5.42s\tremaining: 20.9s\n",
      "206:\tlearn: 0.5241324\ttotal: 5.45s\tremaining: 20.9s\n",
      "207:\tlearn: 0.5237429\ttotal: 5.48s\tremaining: 20.9s\n",
      "208:\tlearn: 0.5231841\ttotal: 5.51s\tremaining: 20.8s\n",
      "209:\tlearn: 0.5227244\ttotal: 5.52s\tremaining: 20.8s\n",
      "210:\tlearn: 0.5223686\ttotal: 5.54s\tremaining: 20.7s\n",
      "211:\tlearn: 0.5218066\ttotal: 5.55s\tremaining: 20.6s\n",
      "212:\tlearn: 0.5215562\ttotal: 5.57s\tremaining: 20.6s\n",
      "213:\tlearn: 0.5211112\ttotal: 5.58s\tremaining: 20.5s\n",
      "214:\tlearn: 0.5207703\ttotal: 5.59s\tremaining: 20.4s\n",
      "215:\tlearn: 0.5202933\ttotal: 5.61s\tremaining: 20.4s\n",
      "216:\tlearn: 0.5198544\ttotal: 5.62s\tremaining: 20.3s\n",
      "217:\tlearn: 0.5194072\ttotal: 5.64s\tremaining: 20.2s\n",
      "218:\tlearn: 0.5189237\ttotal: 5.66s\tremaining: 20.2s\n",
      "219:\tlearn: 0.5185650\ttotal: 5.67s\tremaining: 20.1s\n",
      "220:\tlearn: 0.5179733\ttotal: 5.69s\tremaining: 20s\n",
      "221:\tlearn: 0.5175563\ttotal: 5.7s\tremaining: 20s\n",
      "222:\tlearn: 0.5170007\ttotal: 5.72s\tremaining: 19.9s\n",
      "223:\tlearn: 0.5163098\ttotal: 5.73s\tremaining: 19.9s\n",
      "224:\tlearn: 0.5156859\ttotal: 5.74s\tremaining: 19.8s\n",
      "225:\tlearn: 0.5150888\ttotal: 5.76s\tremaining: 19.7s\n",
      "226:\tlearn: 0.5146404\ttotal: 5.77s\tremaining: 19.7s\n",
      "227:\tlearn: 0.5140581\ttotal: 5.79s\tremaining: 19.6s\n",
      "228:\tlearn: 0.5134744\ttotal: 5.8s\tremaining: 19.5s\n",
      "229:\tlearn: 0.5128428\ttotal: 5.81s\tremaining: 19.5s\n",
      "230:\tlearn: 0.5123905\ttotal: 5.83s\tremaining: 19.4s\n",
      "231:\tlearn: 0.5119377\ttotal: 5.85s\tremaining: 19.4s\n",
      "232:\tlearn: 0.5114903\ttotal: 5.86s\tremaining: 19.3s\n",
      "233:\tlearn: 0.5110746\ttotal: 5.88s\tremaining: 19.2s\n",
      "234:\tlearn: 0.5107113\ttotal: 5.89s\tremaining: 19.2s\n",
      "235:\tlearn: 0.5101798\ttotal: 5.91s\tremaining: 19.1s\n",
      "236:\tlearn: 0.5098797\ttotal: 5.92s\tremaining: 19.1s\n",
      "237:\tlearn: 0.5095016\ttotal: 5.94s\tremaining: 19s\n",
      "238:\tlearn: 0.5091583\ttotal: 5.95s\tremaining: 18.9s\n",
      "239:\tlearn: 0.5087545\ttotal: 5.96s\tremaining: 18.9s\n",
      "240:\tlearn: 0.5082506\ttotal: 5.98s\tremaining: 18.8s\n",
      "241:\tlearn: 0.5076573\ttotal: 5.99s\tremaining: 18.8s\n",
      "242:\tlearn: 0.5072463\ttotal: 6s\tremaining: 18.7s\n",
      "243:\tlearn: 0.5068227\ttotal: 6.02s\tremaining: 18.6s\n",
      "244:\tlearn: 0.5063432\ttotal: 6.04s\tremaining: 18.6s\n",
      "245:\tlearn: 0.5058721\ttotal: 6.05s\tremaining: 18.6s\n",
      "246:\tlearn: 0.5053149\ttotal: 6.07s\tremaining: 18.5s\n",
      "247:\tlearn: 0.5048668\ttotal: 6.08s\tremaining: 18.5s\n",
      "248:\tlearn: 0.5045368\ttotal: 6.1s\tremaining: 18.4s\n",
      "249:\tlearn: 0.5041297\ttotal: 6.11s\tremaining: 18.3s\n",
      "250:\tlearn: 0.5036263\ttotal: 6.13s\tremaining: 18.3s\n",
      "251:\tlearn: 0.5032723\ttotal: 6.14s\tremaining: 18.2s\n",
      "252:\tlearn: 0.5028259\ttotal: 6.16s\tremaining: 18.2s\n",
      "253:\tlearn: 0.5024877\ttotal: 6.17s\tremaining: 18.1s\n",
      "254:\tlearn: 0.5019364\ttotal: 6.18s\tremaining: 18.1s\n",
      "255:\tlearn: 0.5015617\ttotal: 6.2s\tremaining: 18s\n",
      "256:\tlearn: 0.5010341\ttotal: 6.21s\tremaining: 18s\n",
      "257:\tlearn: 0.5004883\ttotal: 6.23s\tremaining: 17.9s\n",
      "258:\tlearn: 0.5002025\ttotal: 6.25s\tremaining: 17.9s\n",
      "259:\tlearn: 0.4997892\ttotal: 6.26s\tremaining: 17.8s\n",
      "260:\tlearn: 0.4993927\ttotal: 6.28s\tremaining: 17.8s\n",
      "261:\tlearn: 0.4988962\ttotal: 6.29s\tremaining: 17.7s\n",
      "262:\tlearn: 0.4984413\ttotal: 6.3s\tremaining: 17.7s\n",
      "263:\tlearn: 0.4979182\ttotal: 6.32s\tremaining: 17.6s\n",
      "264:\tlearn: 0.4972423\ttotal: 6.33s\tremaining: 17.6s\n",
      "265:\tlearn: 0.4966033\ttotal: 6.35s\tremaining: 17.5s\n",
      "266:\tlearn: 0.4962626\ttotal: 6.36s\tremaining: 17.5s\n",
      "267:\tlearn: 0.4955611\ttotal: 6.37s\tremaining: 17.4s\n",
      "268:\tlearn: 0.4949959\ttotal: 6.39s\tremaining: 17.4s\n",
      "269:\tlearn: 0.4945252\ttotal: 6.4s\tremaining: 17.3s\n",
      "270:\tlearn: 0.4942331\ttotal: 6.42s\tremaining: 17.3s\n",
      "271:\tlearn: 0.4938931\ttotal: 6.43s\tremaining: 17.2s\n",
      "272:\tlearn: 0.4934934\ttotal: 6.45s\tremaining: 17.2s\n",
      "273:\tlearn: 0.4930223\ttotal: 6.47s\tremaining: 17.1s\n",
      "274:\tlearn: 0.4923943\ttotal: 6.49s\tremaining: 17.1s\n",
      "275:\tlearn: 0.4919119\ttotal: 6.51s\tremaining: 17.1s\n",
      "276:\tlearn: 0.4915403\ttotal: 6.53s\tremaining: 17s\n",
      "277:\tlearn: 0.4912959\ttotal: 6.54s\tremaining: 17s\n",
      "278:\tlearn: 0.4908708\ttotal: 6.56s\tremaining: 16.9s\n",
      "279:\tlearn: 0.4905132\ttotal: 6.57s\tremaining: 16.9s\n",
      "280:\tlearn: 0.4901626\ttotal: 6.59s\tremaining: 16.9s\n",
      "281:\tlearn: 0.4897397\ttotal: 6.6s\tremaining: 16.8s\n",
      "282:\tlearn: 0.4892911\ttotal: 6.62s\tremaining: 16.8s\n",
      "283:\tlearn: 0.4887590\ttotal: 6.64s\tremaining: 16.7s\n",
      "284:\tlearn: 0.4884088\ttotal: 6.66s\tremaining: 16.7s\n",
      "285:\tlearn: 0.4879105\ttotal: 6.68s\tremaining: 16.7s\n",
      "286:\tlearn: 0.4875598\ttotal: 6.69s\tremaining: 16.6s\n",
      "287:\tlearn: 0.4872714\ttotal: 6.71s\tremaining: 16.6s\n",
      "288:\tlearn: 0.4870237\ttotal: 6.72s\tremaining: 16.5s\n",
      "289:\tlearn: 0.4865654\ttotal: 6.74s\tremaining: 16.5s\n",
      "290:\tlearn: 0.4862268\ttotal: 6.75s\tremaining: 16.5s\n",
      "291:\tlearn: 0.4859406\ttotal: 6.77s\tremaining: 16.4s\n",
      "292:\tlearn: 0.4855728\ttotal: 6.79s\tremaining: 16.4s\n",
      "293:\tlearn: 0.4849987\ttotal: 6.8s\tremaining: 16.3s\n",
      "294:\tlearn: 0.4846380\ttotal: 6.82s\tremaining: 16.3s\n",
      "295:\tlearn: 0.4842170\ttotal: 6.84s\tremaining: 16.3s\n",
      "296:\tlearn: 0.4837437\ttotal: 6.86s\tremaining: 16.2s\n",
      "297:\tlearn: 0.4832849\ttotal: 6.87s\tremaining: 16.2s\n",
      "298:\tlearn: 0.4829129\ttotal: 6.89s\tremaining: 16.2s\n",
      "299:\tlearn: 0.4823209\ttotal: 6.91s\tremaining: 16.1s\n",
      "300:\tlearn: 0.4819707\ttotal: 6.92s\tremaining: 16.1s\n",
      "301:\tlearn: 0.4815649\ttotal: 6.94s\tremaining: 16s\n",
      "302:\tlearn: 0.4812009\ttotal: 6.96s\tremaining: 16s\n",
      "303:\tlearn: 0.4808222\ttotal: 6.97s\tremaining: 16s\n",
      "304:\tlearn: 0.4806100\ttotal: 6.99s\tremaining: 15.9s\n",
      "305:\tlearn: 0.4801623\ttotal: 7s\tremaining: 15.9s\n",
      "306:\tlearn: 0.4798631\ttotal: 7.02s\tremaining: 15.8s\n",
      "307:\tlearn: 0.4794831\ttotal: 7.04s\tremaining: 15.8s\n",
      "308:\tlearn: 0.4793064\ttotal: 7.06s\tremaining: 15.8s\n",
      "309:\tlearn: 0.4790100\ttotal: 7.08s\tremaining: 15.7s\n",
      "310:\tlearn: 0.4784546\ttotal: 7.1s\tremaining: 15.7s\n",
      "311:\tlearn: 0.4779015\ttotal: 7.11s\tremaining: 15.7s\n",
      "312:\tlearn: 0.4775576\ttotal: 7.13s\tremaining: 15.6s\n",
      "313:\tlearn: 0.4773282\ttotal: 7.14s\tremaining: 15.6s\n",
      "314:\tlearn: 0.4770288\ttotal: 7.16s\tremaining: 15.6s\n",
      "315:\tlearn: 0.4765969\ttotal: 7.17s\tremaining: 15.5s\n",
      "316:\tlearn: 0.4762694\ttotal: 7.19s\tremaining: 15.5s\n",
      "317:\tlearn: 0.4757780\ttotal: 7.2s\tremaining: 15.4s\n",
      "318:\tlearn: 0.4754868\ttotal: 7.21s\tremaining: 15.4s\n",
      "319:\tlearn: 0.4751895\ttotal: 7.23s\tremaining: 15.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320:\tlearn: 0.4748569\ttotal: 7.25s\tremaining: 15.3s\n",
      "321:\tlearn: 0.4747175\ttotal: 7.26s\tremaining: 15.3s\n",
      "322:\tlearn: 0.4743182\ttotal: 7.28s\tremaining: 15.3s\n",
      "323:\tlearn: 0.4739985\ttotal: 7.3s\tremaining: 15.2s\n",
      "324:\tlearn: 0.4736159\ttotal: 7.31s\tremaining: 15.2s\n",
      "325:\tlearn: 0.4733088\ttotal: 7.33s\tremaining: 15.1s\n",
      "326:\tlearn: 0.4728614\ttotal: 7.34s\tremaining: 15.1s\n",
      "327:\tlearn: 0.4724480\ttotal: 7.35s\tremaining: 15.1s\n",
      "328:\tlearn: 0.4722143\ttotal: 7.37s\tremaining: 15s\n",
      "329:\tlearn: 0.4717670\ttotal: 7.38s\tremaining: 15s\n",
      "330:\tlearn: 0.4713715\ttotal: 7.4s\tremaining: 15s\n",
      "331:\tlearn: 0.4708150\ttotal: 7.41s\tremaining: 14.9s\n",
      "332:\tlearn: 0.4704227\ttotal: 7.42s\tremaining: 14.9s\n",
      "333:\tlearn: 0.4700822\ttotal: 7.45s\tremaining: 14.8s\n",
      "334:\tlearn: 0.4698303\ttotal: 7.46s\tremaining: 14.8s\n",
      "335:\tlearn: 0.4694554\ttotal: 7.48s\tremaining: 14.8s\n",
      "336:\tlearn: 0.4691409\ttotal: 7.49s\tremaining: 14.7s\n",
      "337:\tlearn: 0.4687304\ttotal: 7.5s\tremaining: 14.7s\n",
      "338:\tlearn: 0.4685656\ttotal: 7.52s\tremaining: 14.7s\n",
      "339:\tlearn: 0.4682860\ttotal: 7.53s\tremaining: 14.6s\n",
      "340:\tlearn: 0.4679413\ttotal: 7.55s\tremaining: 14.6s\n",
      "341:\tlearn: 0.4676375\ttotal: 7.56s\tremaining: 14.5s\n",
      "342:\tlearn: 0.4670822\ttotal: 7.57s\tremaining: 14.5s\n",
      "343:\tlearn: 0.4667054\ttotal: 7.59s\tremaining: 14.5s\n",
      "344:\tlearn: 0.4664436\ttotal: 7.6s\tremaining: 14.4s\n",
      "345:\tlearn: 0.4661786\ttotal: 7.62s\tremaining: 14.4s\n",
      "346:\tlearn: 0.4656305\ttotal: 7.63s\tremaining: 14.4s\n",
      "347:\tlearn: 0.4653588\ttotal: 7.65s\tremaining: 14.3s\n",
      "348:\tlearn: 0.4650274\ttotal: 7.67s\tremaining: 14.3s\n",
      "349:\tlearn: 0.4646185\ttotal: 7.68s\tremaining: 14.3s\n",
      "350:\tlearn: 0.4642829\ttotal: 7.7s\tremaining: 14.2s\n",
      "351:\tlearn: 0.4640522\ttotal: 7.71s\tremaining: 14.2s\n",
      "352:\tlearn: 0.4637297\ttotal: 7.73s\tremaining: 14.2s\n",
      "353:\tlearn: 0.4633785\ttotal: 7.75s\tremaining: 14.1s\n",
      "354:\tlearn: 0.4629398\ttotal: 7.76s\tremaining: 14.1s\n",
      "355:\tlearn: 0.4625446\ttotal: 7.78s\tremaining: 14.1s\n",
      "356:\tlearn: 0.4621234\ttotal: 7.79s\tremaining: 14s\n",
      "357:\tlearn: 0.4617821\ttotal: 7.81s\tremaining: 14s\n",
      "358:\tlearn: 0.4615254\ttotal: 7.83s\tremaining: 14s\n",
      "359:\tlearn: 0.4611022\ttotal: 7.85s\tremaining: 14s\n",
      "360:\tlearn: 0.4606677\ttotal: 7.87s\tremaining: 13.9s\n",
      "361:\tlearn: 0.4603700\ttotal: 7.88s\tremaining: 13.9s\n",
      "362:\tlearn: 0.4601046\ttotal: 7.9s\tremaining: 13.9s\n",
      "363:\tlearn: 0.4597904\ttotal: 7.92s\tremaining: 13.8s\n",
      "364:\tlearn: 0.4593618\ttotal: 7.93s\tremaining: 13.8s\n",
      "365:\tlearn: 0.4589734\ttotal: 7.95s\tremaining: 13.8s\n",
      "366:\tlearn: 0.4586268\ttotal: 7.97s\tremaining: 13.7s\n",
      "367:\tlearn: 0.4582523\ttotal: 7.98s\tremaining: 13.7s\n",
      "368:\tlearn: 0.4578572\ttotal: 8s\tremaining: 13.7s\n",
      "369:\tlearn: 0.4574246\ttotal: 8.02s\tremaining: 13.7s\n",
      "370:\tlearn: 0.4569544\ttotal: 8.04s\tremaining: 13.6s\n",
      "371:\tlearn: 0.4568024\ttotal: 8.06s\tremaining: 13.6s\n",
      "372:\tlearn: 0.4562387\ttotal: 8.07s\tremaining: 13.6s\n",
      "373:\tlearn: 0.4558810\ttotal: 8.09s\tremaining: 13.5s\n",
      "374:\tlearn: 0.4554271\ttotal: 8.1s\tremaining: 13.5s\n",
      "375:\tlearn: 0.4549663\ttotal: 8.12s\tremaining: 13.5s\n",
      "376:\tlearn: 0.4546588\ttotal: 8.14s\tremaining: 13.4s\n",
      "377:\tlearn: 0.4543209\ttotal: 8.15s\tremaining: 13.4s\n",
      "378:\tlearn: 0.4540726\ttotal: 8.17s\tremaining: 13.4s\n",
      "379:\tlearn: 0.4537575\ttotal: 8.18s\tremaining: 13.3s\n",
      "380:\tlearn: 0.4535076\ttotal: 8.2s\tremaining: 13.3s\n",
      "381:\tlearn: 0.4533243\ttotal: 8.22s\tremaining: 13.3s\n",
      "382:\tlearn: 0.4530060\ttotal: 8.23s\tremaining: 13.3s\n",
      "383:\tlearn: 0.4526860\ttotal: 8.25s\tremaining: 13.2s\n",
      "384:\tlearn: 0.4524203\ttotal: 8.27s\tremaining: 13.2s\n",
      "385:\tlearn: 0.4521798\ttotal: 8.28s\tremaining: 13.2s\n",
      "386:\tlearn: 0.4520362\ttotal: 8.3s\tremaining: 13.1s\n",
      "387:\tlearn: 0.4516814\ttotal: 8.31s\tremaining: 13.1s\n",
      "388:\tlearn: 0.4513711\ttotal: 8.33s\tremaining: 13.1s\n",
      "389:\tlearn: 0.4508629\ttotal: 8.34s\tremaining: 13s\n",
      "390:\tlearn: 0.4503960\ttotal: 8.36s\tremaining: 13s\n",
      "391:\tlearn: 0.4499205\ttotal: 8.37s\tremaining: 13s\n",
      "392:\tlearn: 0.4496030\ttotal: 8.39s\tremaining: 13s\n",
      "393:\tlearn: 0.4492981\ttotal: 8.41s\tremaining: 12.9s\n",
      "394:\tlearn: 0.4490363\ttotal: 8.43s\tremaining: 12.9s\n",
      "395:\tlearn: 0.4486817\ttotal: 8.45s\tremaining: 12.9s\n",
      "396:\tlearn: 0.4481378\ttotal: 8.46s\tremaining: 12.9s\n",
      "397:\tlearn: 0.4478952\ttotal: 8.48s\tremaining: 12.8s\n",
      "398:\tlearn: 0.4474351\ttotal: 8.49s\tremaining: 12.8s\n",
      "399:\tlearn: 0.4472071\ttotal: 8.51s\tremaining: 12.8s\n",
      "400:\tlearn: 0.4470099\ttotal: 8.52s\tremaining: 12.7s\n",
      "401:\tlearn: 0.4466273\ttotal: 8.54s\tremaining: 12.7s\n",
      "402:\tlearn: 0.4464078\ttotal: 8.55s\tremaining: 12.7s\n",
      "403:\tlearn: 0.4461484\ttotal: 8.57s\tremaining: 12.6s\n",
      "404:\tlearn: 0.4457083\ttotal: 8.59s\tremaining: 12.6s\n",
      "405:\tlearn: 0.4454502\ttotal: 8.61s\tremaining: 12.6s\n",
      "406:\tlearn: 0.4450728\ttotal: 8.63s\tremaining: 12.6s\n",
      "407:\tlearn: 0.4446051\ttotal: 8.64s\tremaining: 12.5s\n",
      "408:\tlearn: 0.4444752\ttotal: 8.66s\tremaining: 12.5s\n",
      "409:\tlearn: 0.4442320\ttotal: 8.68s\tremaining: 12.5s\n",
      "410:\tlearn: 0.4438274\ttotal: 8.69s\tremaining: 12.5s\n",
      "411:\tlearn: 0.4435222\ttotal: 8.71s\tremaining: 12.4s\n",
      "412:\tlearn: 0.4432224\ttotal: 8.72s\tremaining: 12.4s\n",
      "413:\tlearn: 0.4429620\ttotal: 8.74s\tremaining: 12.4s\n",
      "414:\tlearn: 0.4426019\ttotal: 8.75s\tremaining: 12.3s\n",
      "415:\tlearn: 0.4422809\ttotal: 8.77s\tremaining: 12.3s\n",
      "416:\tlearn: 0.4420708\ttotal: 8.78s\tremaining: 12.3s\n",
      "417:\tlearn: 0.4416626\ttotal: 8.79s\tremaining: 12.2s\n",
      "418:\tlearn: 0.4411754\ttotal: 8.81s\tremaining: 12.2s\n",
      "419:\tlearn: 0.4407176\ttotal: 8.83s\tremaining: 12.2s\n",
      "420:\tlearn: 0.4403259\ttotal: 8.85s\tremaining: 12.2s\n",
      "421:\tlearn: 0.4400886\ttotal: 8.86s\tremaining: 12.1s\n",
      "422:\tlearn: 0.4398463\ttotal: 8.88s\tremaining: 12.1s\n",
      "423:\tlearn: 0.4394185\ttotal: 8.89s\tremaining: 12.1s\n",
      "424:\tlearn: 0.4390029\ttotal: 8.9s\tremaining: 12s\n",
      "425:\tlearn: 0.4388408\ttotal: 8.92s\tremaining: 12s\n",
      "426:\tlearn: 0.4384054\ttotal: 8.93s\tremaining: 12s\n",
      "427:\tlearn: 0.4377878\ttotal: 8.95s\tremaining: 12s\n",
      "428:\tlearn: 0.4375673\ttotal: 8.96s\tremaining: 11.9s\n",
      "429:\tlearn: 0.4373366\ttotal: 8.97s\tremaining: 11.9s\n",
      "430:\tlearn: 0.4369405\ttotal: 8.99s\tremaining: 11.9s\n",
      "431:\tlearn: 0.4367634\ttotal: 9.01s\tremaining: 11.8s\n",
      "432:\tlearn: 0.4364665\ttotal: 9.02s\tremaining: 11.8s\n",
      "433:\tlearn: 0.4361500\ttotal: 9.04s\tremaining: 11.8s\n",
      "434:\tlearn: 0.4357657\ttotal: 9.06s\tremaining: 11.8s\n",
      "435:\tlearn: 0.4353099\ttotal: 9.07s\tremaining: 11.7s\n",
      "436:\tlearn: 0.4350145\ttotal: 9.09s\tremaining: 11.7s\n",
      "437:\tlearn: 0.4348128\ttotal: 9.1s\tremaining: 11.7s\n",
      "438:\tlearn: 0.4342849\ttotal: 9.13s\tremaining: 11.7s\n",
      "439:\tlearn: 0.4338981\ttotal: 9.15s\tremaining: 11.6s\n",
      "440:\tlearn: 0.4336131\ttotal: 9.17s\tremaining: 11.6s\n",
      "441:\tlearn: 0.4332037\ttotal: 9.2s\tremaining: 11.6s\n",
      "442:\tlearn: 0.4330726\ttotal: 9.23s\tremaining: 11.6s\n",
      "443:\tlearn: 0.4328108\ttotal: 9.25s\tremaining: 11.6s\n",
      "444:\tlearn: 0.4325931\ttotal: 9.28s\tremaining: 11.6s\n",
      "445:\tlearn: 0.4320377\ttotal: 9.3s\tremaining: 11.5s\n",
      "446:\tlearn: 0.4316586\ttotal: 9.32s\tremaining: 11.5s\n",
      "447:\tlearn: 0.4314655\ttotal: 9.33s\tremaining: 11.5s\n",
      "448:\tlearn: 0.4311168\ttotal: 9.35s\tremaining: 11.5s\n",
      "449:\tlearn: 0.4306798\ttotal: 9.37s\tremaining: 11.4s\n",
      "450:\tlearn: 0.4303664\ttotal: 9.39s\tremaining: 11.4s\n",
      "451:\tlearn: 0.4301359\ttotal: 9.42s\tremaining: 11.4s\n",
      "452:\tlearn: 0.4297726\ttotal: 9.44s\tremaining: 11.4s\n",
      "453:\tlearn: 0.4294027\ttotal: 9.46s\tremaining: 11.4s\n",
      "454:\tlearn: 0.4291144\ttotal: 9.49s\tremaining: 11.4s\n",
      "455:\tlearn: 0.4289916\ttotal: 9.52s\tremaining: 11.4s\n",
      "456:\tlearn: 0.4286433\ttotal: 9.56s\tremaining: 11.4s\n",
      "457:\tlearn: 0.4284228\ttotal: 9.59s\tremaining: 11.3s\n",
      "458:\tlearn: 0.4280244\ttotal: 9.62s\tremaining: 11.3s\n",
      "459:\tlearn: 0.4277582\ttotal: 9.65s\tremaining: 11.3s\n",
      "460:\tlearn: 0.4274285\ttotal: 9.67s\tremaining: 11.3s\n",
      "461:\tlearn: 0.4271457\ttotal: 9.69s\tremaining: 11.3s\n",
      "462:\tlearn: 0.4268778\ttotal: 9.7s\tremaining: 11.3s\n",
      "463:\tlearn: 0.4266241\ttotal: 9.72s\tremaining: 11.2s\n",
      "464:\tlearn: 0.4262682\ttotal: 9.74s\tremaining: 11.2s\n",
      "465:\tlearn: 0.4259536\ttotal: 9.76s\tremaining: 11.2s\n",
      "466:\tlearn: 0.4255617\ttotal: 9.78s\tremaining: 11.2s\n",
      "467:\tlearn: 0.4254023\ttotal: 9.8s\tremaining: 11.1s\n",
      "468:\tlearn: 0.4249841\ttotal: 9.83s\tremaining: 11.1s\n",
      "469:\tlearn: 0.4244113\ttotal: 9.87s\tremaining: 11.1s\n",
      "470:\tlearn: 0.4241959\ttotal: 9.89s\tremaining: 11.1s\n",
      "471:\tlearn: 0.4239488\ttotal: 9.91s\tremaining: 11.1s\n",
      "472:\tlearn: 0.4235829\ttotal: 9.93s\tremaining: 11.1s\n",
      "473:\tlearn: 0.4233142\ttotal: 9.94s\tremaining: 11s\n",
      "474:\tlearn: 0.4231291\ttotal: 9.95s\tremaining: 11s\n",
      "475:\tlearn: 0.4228508\ttotal: 9.97s\tremaining: 11s\n",
      "476:\tlearn: 0.4226427\ttotal: 9.98s\tremaining: 10.9s\n",
      "477:\tlearn: 0.4223223\ttotal: 10s\tremaining: 10.9s\n",
      "478:\tlearn: 0.4220293\ttotal: 10s\tremaining: 10.9s\n",
      "479:\tlearn: 0.4218387\ttotal: 10s\tremaining: 10.9s\n",
      "480:\tlearn: 0.4216370\ttotal: 10s\tremaining: 10.8s\n",
      "481:\tlearn: 0.4214917\ttotal: 10.1s\tremaining: 10.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482:\tlearn: 0.4212768\ttotal: 10.1s\tremaining: 10.8s\n",
      "483:\tlearn: 0.4210115\ttotal: 10.1s\tremaining: 10.8s\n",
      "484:\tlearn: 0.4203825\ttotal: 10.1s\tremaining: 10.7s\n",
      "485:\tlearn: 0.4201281\ttotal: 10.1s\tremaining: 10.7s\n",
      "486:\tlearn: 0.4197244\ttotal: 10.1s\tremaining: 10.7s\n",
      "487:\tlearn: 0.4194956\ttotal: 10.2s\tremaining: 10.7s\n",
      "488:\tlearn: 0.4191567\ttotal: 10.2s\tremaining: 10.6s\n",
      "489:\tlearn: 0.4188524\ttotal: 10.2s\tremaining: 10.6s\n",
      "490:\tlearn: 0.4185775\ttotal: 10.2s\tremaining: 10.6s\n",
      "491:\tlearn: 0.4181282\ttotal: 10.2s\tremaining: 10.5s\n",
      "492:\tlearn: 0.4178314\ttotal: 10.2s\tremaining: 10.5s\n",
      "493:\tlearn: 0.4173784\ttotal: 10.2s\tremaining: 10.5s\n",
      "494:\tlearn: 0.4170097\ttotal: 10.3s\tremaining: 10.5s\n",
      "495:\tlearn: 0.4166377\ttotal: 10.3s\tremaining: 10.4s\n",
      "496:\tlearn: 0.4162923\ttotal: 10.3s\tremaining: 10.4s\n",
      "497:\tlearn: 0.4160730\ttotal: 10.4s\tremaining: 10.4s\n",
      "498:\tlearn: 0.4156808\ttotal: 10.4s\tremaining: 10.4s\n",
      "499:\tlearn: 0.4153898\ttotal: 10.4s\tremaining: 10.4s\n",
      "500:\tlearn: 0.4151096\ttotal: 10.4s\tremaining: 10.4s\n",
      "501:\tlearn: 0.4148862\ttotal: 10.4s\tremaining: 10.4s\n",
      "502:\tlearn: 0.4146750\ttotal: 10.5s\tremaining: 10.3s\n",
      "503:\tlearn: 0.4141898\ttotal: 10.5s\tremaining: 10.3s\n",
      "504:\tlearn: 0.4138972\ttotal: 10.5s\tremaining: 10.3s\n",
      "505:\tlearn: 0.4137468\ttotal: 10.5s\tremaining: 10.3s\n",
      "506:\tlearn: 0.4134098\ttotal: 10.6s\tremaining: 10.3s\n",
      "507:\tlearn: 0.4131354\ttotal: 10.6s\tremaining: 10.2s\n",
      "508:\tlearn: 0.4128022\ttotal: 10.6s\tremaining: 10.2s\n",
      "509:\tlearn: 0.4123616\ttotal: 10.7s\tremaining: 10.2s\n",
      "510:\tlearn: 0.4120695\ttotal: 10.7s\tremaining: 10.2s\n",
      "511:\tlearn: 0.4117365\ttotal: 10.7s\tremaining: 10.2s\n",
      "512:\tlearn: 0.4113458\ttotal: 10.7s\tremaining: 10.2s\n",
      "513:\tlearn: 0.4111250\ttotal: 10.8s\tremaining: 10.2s\n",
      "514:\tlearn: 0.4108780\ttotal: 10.8s\tremaining: 10.1s\n",
      "515:\tlearn: 0.4106828\ttotal: 10.8s\tremaining: 10.1s\n",
      "516:\tlearn: 0.4103942\ttotal: 10.8s\tremaining: 10.1s\n",
      "517:\tlearn: 0.4101150\ttotal: 10.8s\tremaining: 10.1s\n",
      "518:\tlearn: 0.4097831\ttotal: 10.8s\tremaining: 10s\n",
      "519:\tlearn: 0.4093861\ttotal: 10.8s\tremaining: 10s\n",
      "520:\tlearn: 0.4091784\ttotal: 10.9s\tremaining: 9.98s\n",
      "521:\tlearn: 0.4088236\ttotal: 10.9s\tremaining: 9.95s\n",
      "522:\tlearn: 0.4086338\ttotal: 10.9s\tremaining: 9.92s\n",
      "523:\tlearn: 0.4083937\ttotal: 10.9s\tremaining: 9.9s\n",
      "524:\tlearn: 0.4079674\ttotal: 10.9s\tremaining: 9.88s\n",
      "525:\tlearn: 0.4076991\ttotal: 10.9s\tremaining: 9.85s\n",
      "526:\tlearn: 0.4073848\ttotal: 10.9s\tremaining: 9.83s\n",
      "527:\tlearn: 0.4069636\ttotal: 11s\tremaining: 9.8s\n",
      "528:\tlearn: 0.4066068\ttotal: 11s\tremaining: 9.77s\n",
      "529:\tlearn: 0.4063521\ttotal: 11s\tremaining: 9.75s\n",
      "530:\tlearn: 0.4060849\ttotal: 11s\tremaining: 9.72s\n",
      "531:\tlearn: 0.4057762\ttotal: 11s\tremaining: 9.69s\n",
      "532:\tlearn: 0.4055515\ttotal: 11s\tremaining: 9.67s\n",
      "533:\tlearn: 0.4053607\ttotal: 11s\tremaining: 9.64s\n",
      "534:\tlearn: 0.4049363\ttotal: 11.1s\tremaining: 9.61s\n",
      "535:\tlearn: 0.4046045\ttotal: 11.1s\tremaining: 9.59s\n",
      "536:\tlearn: 0.4043559\ttotal: 11.1s\tremaining: 9.56s\n",
      "537:\tlearn: 0.4040453\ttotal: 11.1s\tremaining: 9.54s\n",
      "538:\tlearn: 0.4038198\ttotal: 11.1s\tremaining: 9.52s\n",
      "539:\tlearn: 0.4036174\ttotal: 11.1s\tremaining: 9.49s\n",
      "540:\tlearn: 0.4033311\ttotal: 11.2s\tremaining: 9.46s\n",
      "541:\tlearn: 0.4030495\ttotal: 11.2s\tremaining: 9.44s\n",
      "542:\tlearn: 0.4028022\ttotal: 11.2s\tremaining: 9.41s\n",
      "543:\tlearn: 0.4026323\ttotal: 11.2s\tremaining: 9.39s\n",
      "544:\tlearn: 0.4023053\ttotal: 11.2s\tremaining: 9.36s\n",
      "545:\tlearn: 0.4020549\ttotal: 11.2s\tremaining: 9.33s\n",
      "546:\tlearn: 0.4016588\ttotal: 11.2s\tremaining: 9.31s\n",
      "547:\tlearn: 0.4014186\ttotal: 11.3s\tremaining: 9.28s\n",
      "548:\tlearn: 0.4010392\ttotal: 11.3s\tremaining: 9.26s\n",
      "549:\tlearn: 0.4008192\ttotal: 11.3s\tremaining: 9.23s\n",
      "550:\tlearn: 0.4005211\ttotal: 11.3s\tremaining: 9.21s\n",
      "551:\tlearn: 0.4002729\ttotal: 11.3s\tremaining: 9.19s\n",
      "552:\tlearn: 0.3999944\ttotal: 11.3s\tremaining: 9.16s\n",
      "553:\tlearn: 0.3995507\ttotal: 11.3s\tremaining: 9.13s\n",
      "554:\tlearn: 0.3992193\ttotal: 11.4s\tremaining: 9.11s\n",
      "555:\tlearn: 0.3989459\ttotal: 11.4s\tremaining: 9.08s\n",
      "556:\tlearn: 0.3985706\ttotal: 11.4s\tremaining: 9.06s\n",
      "557:\tlearn: 0.3981818\ttotal: 11.4s\tremaining: 9.03s\n",
      "558:\tlearn: 0.3980029\ttotal: 11.4s\tremaining: 9.01s\n",
      "559:\tlearn: 0.3976002\ttotal: 11.4s\tremaining: 8.98s\n",
      "560:\tlearn: 0.3973490\ttotal: 11.4s\tremaining: 8.96s\n",
      "561:\tlearn: 0.3970288\ttotal: 11.5s\tremaining: 8.93s\n",
      "562:\tlearn: 0.3968105\ttotal: 11.5s\tremaining: 8.91s\n",
      "563:\tlearn: 0.3966312\ttotal: 11.5s\tremaining: 8.88s\n",
      "564:\tlearn: 0.3964217\ttotal: 11.5s\tremaining: 8.86s\n",
      "565:\tlearn: 0.3962950\ttotal: 11.5s\tremaining: 8.84s\n",
      "566:\tlearn: 0.3959561\ttotal: 11.5s\tremaining: 8.81s\n",
      "567:\tlearn: 0.3957895\ttotal: 11.6s\tremaining: 8.79s\n",
      "568:\tlearn: 0.3954569\ttotal: 11.6s\tremaining: 8.76s\n",
      "569:\tlearn: 0.3952818\ttotal: 11.6s\tremaining: 8.74s\n",
      "570:\tlearn: 0.3950128\ttotal: 11.6s\tremaining: 8.71s\n",
      "571:\tlearn: 0.3946170\ttotal: 11.6s\tremaining: 8.69s\n",
      "572:\tlearn: 0.3944817\ttotal: 11.6s\tremaining: 8.66s\n",
      "573:\tlearn: 0.3942346\ttotal: 11.6s\tremaining: 8.63s\n",
      "574:\tlearn: 0.3937912\ttotal: 11.6s\tremaining: 8.61s\n",
      "575:\tlearn: 0.3934795\ttotal: 11.7s\tremaining: 8.59s\n",
      "576:\tlearn: 0.3932832\ttotal: 11.7s\tremaining: 8.57s\n",
      "577:\tlearn: 0.3927719\ttotal: 11.7s\tremaining: 8.54s\n",
      "578:\tlearn: 0.3926126\ttotal: 11.7s\tremaining: 8.52s\n",
      "579:\tlearn: 0.3923928\ttotal: 11.7s\tremaining: 8.49s\n",
      "580:\tlearn: 0.3920081\ttotal: 11.7s\tremaining: 8.47s\n",
      "581:\tlearn: 0.3917291\ttotal: 11.8s\tremaining: 8.45s\n",
      "582:\tlearn: 0.3914100\ttotal: 11.8s\tremaining: 8.42s\n",
      "583:\tlearn: 0.3911666\ttotal: 11.8s\tremaining: 8.4s\n",
      "584:\tlearn: 0.3909023\ttotal: 11.8s\tremaining: 8.37s\n",
      "585:\tlearn: 0.3906526\ttotal: 11.8s\tremaining: 8.35s\n",
      "586:\tlearn: 0.3904604\ttotal: 11.8s\tremaining: 8.32s\n",
      "587:\tlearn: 0.3902235\ttotal: 11.8s\tremaining: 8.3s\n",
      "588:\tlearn: 0.3899062\ttotal: 11.9s\tremaining: 8.28s\n",
      "589:\tlearn: 0.3896372\ttotal: 11.9s\tremaining: 8.25s\n",
      "590:\tlearn: 0.3894708\ttotal: 11.9s\tremaining: 8.23s\n",
      "591:\tlearn: 0.3892843\ttotal: 11.9s\tremaining: 8.21s\n",
      "592:\tlearn: 0.3890438\ttotal: 11.9s\tremaining: 8.19s\n",
      "593:\tlearn: 0.3888415\ttotal: 11.9s\tremaining: 8.16s\n",
      "594:\tlearn: 0.3885402\ttotal: 12s\tremaining: 8.14s\n",
      "595:\tlearn: 0.3881369\ttotal: 12s\tremaining: 8.11s\n",
      "596:\tlearn: 0.3879058\ttotal: 12s\tremaining: 8.09s\n",
      "597:\tlearn: 0.3875450\ttotal: 12s\tremaining: 8.06s\n",
      "598:\tlearn: 0.3873546\ttotal: 12s\tremaining: 8.04s\n",
      "599:\tlearn: 0.3871996\ttotal: 12s\tremaining: 8.02s\n",
      "600:\tlearn: 0.3869109\ttotal: 12s\tremaining: 7.99s\n",
      "601:\tlearn: 0.3866485\ttotal: 12.1s\tremaining: 7.97s\n",
      "602:\tlearn: 0.3861871\ttotal: 12.1s\tremaining: 7.94s\n",
      "603:\tlearn: 0.3859210\ttotal: 12.1s\tremaining: 7.92s\n",
      "604:\tlearn: 0.3856508\ttotal: 12.1s\tremaining: 7.9s\n",
      "605:\tlearn: 0.3852646\ttotal: 12.1s\tremaining: 7.88s\n",
      "606:\tlearn: 0.3850814\ttotal: 12.1s\tremaining: 7.85s\n",
      "607:\tlearn: 0.3848570\ttotal: 12.1s\tremaining: 7.83s\n",
      "608:\tlearn: 0.3845897\ttotal: 12.2s\tremaining: 7.81s\n",
      "609:\tlearn: 0.3844367\ttotal: 12.2s\tremaining: 7.78s\n",
      "610:\tlearn: 0.3842211\ttotal: 12.2s\tremaining: 7.76s\n",
      "611:\tlearn: 0.3839088\ttotal: 12.2s\tremaining: 7.74s\n",
      "612:\tlearn: 0.3834983\ttotal: 12.2s\tremaining: 7.71s\n",
      "613:\tlearn: 0.3833149\ttotal: 12.2s\tremaining: 7.69s\n",
      "614:\tlearn: 0.3829046\ttotal: 12.2s\tremaining: 7.66s\n",
      "615:\tlearn: 0.3826441\ttotal: 12.3s\tremaining: 7.64s\n",
      "616:\tlearn: 0.3824224\ttotal: 12.3s\tremaining: 7.62s\n",
      "617:\tlearn: 0.3821169\ttotal: 12.3s\tremaining: 7.6s\n",
      "618:\tlearn: 0.3818699\ttotal: 12.3s\tremaining: 7.58s\n",
      "619:\tlearn: 0.3817136\ttotal: 12.3s\tremaining: 7.55s\n",
      "620:\tlearn: 0.3815022\ttotal: 12.3s\tremaining: 7.53s\n",
      "621:\tlearn: 0.3813396\ttotal: 12.4s\tremaining: 7.51s\n",
      "622:\tlearn: 0.3811280\ttotal: 12.4s\tremaining: 7.48s\n",
      "623:\tlearn: 0.3806453\ttotal: 12.4s\tremaining: 7.46s\n",
      "624:\tlearn: 0.3803163\ttotal: 12.4s\tremaining: 7.44s\n",
      "625:\tlearn: 0.3800351\ttotal: 12.4s\tremaining: 7.41s\n",
      "626:\tlearn: 0.3798256\ttotal: 12.4s\tremaining: 7.39s\n",
      "627:\tlearn: 0.3796550\ttotal: 12.4s\tremaining: 7.37s\n",
      "628:\tlearn: 0.3791903\ttotal: 12.5s\tremaining: 7.34s\n",
      "629:\tlearn: 0.3789708\ttotal: 12.5s\tremaining: 7.32s\n",
      "630:\tlearn: 0.3787075\ttotal: 12.5s\tremaining: 7.3s\n",
      "631:\tlearn: 0.3783064\ttotal: 12.5s\tremaining: 7.28s\n",
      "632:\tlearn: 0.3779987\ttotal: 12.5s\tremaining: 7.26s\n",
      "633:\tlearn: 0.3776678\ttotal: 12.5s\tremaining: 7.24s\n",
      "634:\tlearn: 0.3773758\ttotal: 12.5s\tremaining: 7.21s\n",
      "635:\tlearn: 0.3770489\ttotal: 12.6s\tremaining: 7.19s\n",
      "636:\tlearn: 0.3769343\ttotal: 12.6s\tremaining: 7.17s\n",
      "637:\tlearn: 0.3766590\ttotal: 12.6s\tremaining: 7.14s\n",
      "638:\tlearn: 0.3763830\ttotal: 12.6s\tremaining: 7.12s\n",
      "639:\tlearn: 0.3760143\ttotal: 12.6s\tremaining: 7.1s\n",
      "640:\tlearn: 0.3756516\ttotal: 12.6s\tremaining: 7.08s\n",
      "641:\tlearn: 0.3754559\ttotal: 12.6s\tremaining: 7.05s\n",
      "642:\tlearn: 0.3751825\ttotal: 12.7s\tremaining: 7.03s\n",
      "643:\tlearn: 0.3749376\ttotal: 12.7s\tremaining: 7.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644:\tlearn: 0.3745244\ttotal: 12.7s\tremaining: 6.99s\n",
      "645:\tlearn: 0.3742203\ttotal: 12.7s\tremaining: 6.97s\n",
      "646:\tlearn: 0.3740219\ttotal: 12.7s\tremaining: 6.95s\n",
      "647:\tlearn: 0.3738557\ttotal: 12.7s\tremaining: 6.92s\n",
      "648:\tlearn: 0.3735950\ttotal: 12.8s\tremaining: 6.9s\n",
      "649:\tlearn: 0.3732609\ttotal: 12.8s\tremaining: 6.88s\n",
      "650:\tlearn: 0.3728769\ttotal: 12.8s\tremaining: 6.86s\n",
      "651:\tlearn: 0.3726743\ttotal: 12.8s\tremaining: 6.83s\n",
      "652:\tlearn: 0.3724276\ttotal: 12.8s\tremaining: 6.81s\n",
      "653:\tlearn: 0.3722125\ttotal: 12.8s\tremaining: 6.79s\n",
      "654:\tlearn: 0.3720200\ttotal: 12.8s\tremaining: 6.77s\n",
      "655:\tlearn: 0.3717407\ttotal: 12.9s\tremaining: 6.75s\n",
      "656:\tlearn: 0.3713962\ttotal: 12.9s\tremaining: 6.72s\n",
      "657:\tlearn: 0.3709826\ttotal: 12.9s\tremaining: 6.7s\n",
      "658:\tlearn: 0.3707480\ttotal: 12.9s\tremaining: 6.68s\n",
      "659:\tlearn: 0.3705335\ttotal: 12.9s\tremaining: 6.66s\n",
      "660:\tlearn: 0.3701409\ttotal: 12.9s\tremaining: 6.64s\n",
      "661:\tlearn: 0.3698143\ttotal: 13s\tremaining: 6.62s\n",
      "662:\tlearn: 0.3695166\ttotal: 13s\tremaining: 6.59s\n",
      "663:\tlearn: 0.3693917\ttotal: 13s\tremaining: 6.57s\n",
      "664:\tlearn: 0.3692026\ttotal: 13s\tremaining: 6.55s\n",
      "665:\tlearn: 0.3687454\ttotal: 13s\tremaining: 6.53s\n",
      "666:\tlearn: 0.3685588\ttotal: 13s\tremaining: 6.5s\n",
      "667:\tlearn: 0.3683430\ttotal: 13s\tremaining: 6.48s\n",
      "668:\tlearn: 0.3681010\ttotal: 13.1s\tremaining: 6.46s\n",
      "669:\tlearn: 0.3677982\ttotal: 13.1s\tremaining: 6.44s\n",
      "670:\tlearn: 0.3674908\ttotal: 13.1s\tremaining: 6.41s\n",
      "671:\tlearn: 0.3670728\ttotal: 13.1s\tremaining: 6.39s\n",
      "672:\tlearn: 0.3668658\ttotal: 13.1s\tremaining: 6.37s\n",
      "673:\tlearn: 0.3665792\ttotal: 13.1s\tremaining: 6.35s\n",
      "674:\tlearn: 0.3663518\ttotal: 13.1s\tremaining: 6.33s\n",
      "675:\tlearn: 0.3661398\ttotal: 13.2s\tremaining: 6.31s\n",
      "676:\tlearn: 0.3659924\ttotal: 13.2s\tremaining: 6.29s\n",
      "677:\tlearn: 0.3656643\ttotal: 13.2s\tremaining: 6.26s\n",
      "678:\tlearn: 0.3653533\ttotal: 13.2s\tremaining: 6.24s\n",
      "679:\tlearn: 0.3651302\ttotal: 13.2s\tremaining: 6.22s\n",
      "680:\tlearn: 0.3649004\ttotal: 13.2s\tremaining: 6.2s\n",
      "681:\tlearn: 0.3647074\ttotal: 13.2s\tremaining: 6.18s\n",
      "682:\tlearn: 0.3645281\ttotal: 13.3s\tremaining: 6.15s\n",
      "683:\tlearn: 0.3641972\ttotal: 13.3s\tremaining: 6.13s\n",
      "684:\tlearn: 0.3639746\ttotal: 13.3s\tremaining: 6.11s\n",
      "685:\tlearn: 0.3635595\ttotal: 13.3s\tremaining: 6.09s\n",
      "686:\tlearn: 0.3632360\ttotal: 13.3s\tremaining: 6.07s\n",
      "687:\tlearn: 0.3629977\ttotal: 13.3s\tremaining: 6.05s\n",
      "688:\tlearn: 0.3627296\ttotal: 13.4s\tremaining: 6.03s\n",
      "689:\tlearn: 0.3625626\ttotal: 13.4s\tremaining: 6.01s\n",
      "690:\tlearn: 0.3622940\ttotal: 13.4s\tremaining: 5.98s\n",
      "691:\tlearn: 0.3621149\ttotal: 13.4s\tremaining: 5.96s\n",
      "692:\tlearn: 0.3617274\ttotal: 13.4s\tremaining: 5.94s\n",
      "693:\tlearn: 0.3615758\ttotal: 13.4s\tremaining: 5.92s\n",
      "694:\tlearn: 0.3612449\ttotal: 13.4s\tremaining: 5.9s\n",
      "695:\tlearn: 0.3610403\ttotal: 13.5s\tremaining: 5.88s\n",
      "696:\tlearn: 0.3608334\ttotal: 13.5s\tremaining: 5.85s\n",
      "697:\tlearn: 0.3605886\ttotal: 13.5s\tremaining: 5.83s\n",
      "698:\tlearn: 0.3604352\ttotal: 13.5s\tremaining: 5.81s\n",
      "699:\tlearn: 0.3601806\ttotal: 13.5s\tremaining: 5.79s\n",
      "700:\tlearn: 0.3598327\ttotal: 13.5s\tremaining: 5.77s\n",
      "701:\tlearn: 0.3596245\ttotal: 13.6s\tremaining: 5.75s\n",
      "702:\tlearn: 0.3594451\ttotal: 13.6s\tremaining: 5.73s\n",
      "703:\tlearn: 0.3592534\ttotal: 13.6s\tremaining: 5.71s\n",
      "704:\tlearn: 0.3590176\ttotal: 13.6s\tremaining: 5.69s\n",
      "705:\tlearn: 0.3588910\ttotal: 13.6s\tremaining: 5.67s\n",
      "706:\tlearn: 0.3586866\ttotal: 13.6s\tremaining: 5.65s\n",
      "707:\tlearn: 0.3584173\ttotal: 13.6s\tremaining: 5.63s\n",
      "708:\tlearn: 0.3581945\ttotal: 13.7s\tremaining: 5.61s\n",
      "709:\tlearn: 0.3579877\ttotal: 13.7s\tremaining: 5.59s\n",
      "710:\tlearn: 0.3577078\ttotal: 13.7s\tremaining: 5.57s\n",
      "711:\tlearn: 0.3574288\ttotal: 13.7s\tremaining: 5.55s\n",
      "712:\tlearn: 0.3571848\ttotal: 13.7s\tremaining: 5.53s\n",
      "713:\tlearn: 0.3569056\ttotal: 13.8s\tremaining: 5.51s\n",
      "714:\tlearn: 0.3566390\ttotal: 13.8s\tremaining: 5.49s\n",
      "715:\tlearn: 0.3563325\ttotal: 13.8s\tremaining: 5.47s\n",
      "716:\tlearn: 0.3561022\ttotal: 13.8s\tremaining: 5.45s\n",
      "717:\tlearn: 0.3557405\ttotal: 13.8s\tremaining: 5.43s\n",
      "718:\tlearn: 0.3556219\ttotal: 13.8s\tremaining: 5.41s\n",
      "719:\tlearn: 0.3553511\ttotal: 13.9s\tremaining: 5.39s\n",
      "720:\tlearn: 0.3550949\ttotal: 13.9s\tremaining: 5.37s\n",
      "721:\tlearn: 0.3549007\ttotal: 13.9s\tremaining: 5.35s\n",
      "722:\tlearn: 0.3547444\ttotal: 13.9s\tremaining: 5.33s\n",
      "723:\tlearn: 0.3544946\ttotal: 13.9s\tremaining: 5.31s\n",
      "724:\tlearn: 0.3543381\ttotal: 13.9s\tremaining: 5.29s\n",
      "725:\tlearn: 0.3541111\ttotal: 14s\tremaining: 5.27s\n",
      "726:\tlearn: 0.3538499\ttotal: 14s\tremaining: 5.25s\n",
      "727:\tlearn: 0.3535095\ttotal: 14s\tremaining: 5.23s\n",
      "728:\tlearn: 0.3532531\ttotal: 14s\tremaining: 5.21s\n",
      "729:\tlearn: 0.3530611\ttotal: 14s\tremaining: 5.19s\n",
      "730:\tlearn: 0.3527849\ttotal: 14s\tremaining: 5.17s\n",
      "731:\tlearn: 0.3524624\ttotal: 14.1s\tremaining: 5.15s\n",
      "732:\tlearn: 0.3522606\ttotal: 14.1s\tremaining: 5.13s\n",
      "733:\tlearn: 0.3519913\ttotal: 14.1s\tremaining: 5.11s\n",
      "734:\tlearn: 0.3516798\ttotal: 14.1s\tremaining: 5.09s\n",
      "735:\tlearn: 0.3514551\ttotal: 14.1s\tremaining: 5.07s\n",
      "736:\tlearn: 0.3512631\ttotal: 14.2s\tremaining: 5.05s\n",
      "737:\tlearn: 0.3509668\ttotal: 14.2s\tremaining: 5.03s\n",
      "738:\tlearn: 0.3507863\ttotal: 14.2s\tremaining: 5.01s\n",
      "739:\tlearn: 0.3504855\ttotal: 14.2s\tremaining: 4.99s\n",
      "740:\tlearn: 0.3503273\ttotal: 14.2s\tremaining: 4.97s\n",
      "741:\tlearn: 0.3500918\ttotal: 14.2s\tremaining: 4.95s\n",
      "742:\tlearn: 0.3499261\ttotal: 14.2s\tremaining: 4.93s\n",
      "743:\tlearn: 0.3497950\ttotal: 14.3s\tremaining: 4.91s\n",
      "744:\tlearn: 0.3495313\ttotal: 14.3s\tremaining: 4.89s\n",
      "745:\tlearn: 0.3492625\ttotal: 14.3s\tremaining: 4.87s\n",
      "746:\tlearn: 0.3491383\ttotal: 14.3s\tremaining: 4.84s\n",
      "747:\tlearn: 0.3489725\ttotal: 14.3s\tremaining: 4.83s\n",
      "748:\tlearn: 0.3487576\ttotal: 14.3s\tremaining: 4.81s\n",
      "749:\tlearn: 0.3484666\ttotal: 14.4s\tremaining: 4.79s\n",
      "750:\tlearn: 0.3482380\ttotal: 14.4s\tremaining: 4.76s\n",
      "751:\tlearn: 0.3480267\ttotal: 14.4s\tremaining: 4.75s\n",
      "752:\tlearn: 0.3478713\ttotal: 14.4s\tremaining: 4.72s\n",
      "753:\tlearn: 0.3477059\ttotal: 14.4s\tremaining: 4.7s\n",
      "754:\tlearn: 0.3474490\ttotal: 14.4s\tremaining: 4.68s\n",
      "755:\tlearn: 0.3472265\ttotal: 14.4s\tremaining: 4.66s\n",
      "756:\tlearn: 0.3469468\ttotal: 14.5s\tremaining: 4.64s\n",
      "757:\tlearn: 0.3466915\ttotal: 14.5s\tremaining: 4.62s\n",
      "758:\tlearn: 0.3462912\ttotal: 14.5s\tremaining: 4.6s\n",
      "759:\tlearn: 0.3458921\ttotal: 14.5s\tremaining: 4.58s\n",
      "760:\tlearn: 0.3456238\ttotal: 14.5s\tremaining: 4.56s\n",
      "761:\tlearn: 0.3453137\ttotal: 14.5s\tremaining: 4.54s\n",
      "762:\tlearn: 0.3450358\ttotal: 14.6s\tremaining: 4.52s\n",
      "763:\tlearn: 0.3448814\ttotal: 14.6s\tremaining: 4.5s\n",
      "764:\tlearn: 0.3447728\ttotal: 14.6s\tremaining: 4.48s\n",
      "765:\tlearn: 0.3445740\ttotal: 14.6s\tremaining: 4.46s\n",
      "766:\tlearn: 0.3444730\ttotal: 14.6s\tremaining: 4.44s\n",
      "767:\tlearn: 0.3441117\ttotal: 14.6s\tremaining: 4.42s\n",
      "768:\tlearn: 0.3438400\ttotal: 14.6s\tremaining: 4.4s\n",
      "769:\tlearn: 0.3436636\ttotal: 14.7s\tremaining: 4.38s\n",
      "770:\tlearn: 0.3432303\ttotal: 14.7s\tremaining: 4.36s\n",
      "771:\tlearn: 0.3428882\ttotal: 14.7s\tremaining: 4.34s\n",
      "772:\tlearn: 0.3425936\ttotal: 14.7s\tremaining: 4.32s\n",
      "773:\tlearn: 0.3422840\ttotal: 14.7s\tremaining: 4.29s\n",
      "774:\tlearn: 0.3421511\ttotal: 14.7s\tremaining: 4.27s\n",
      "775:\tlearn: 0.3418605\ttotal: 14.7s\tremaining: 4.26s\n",
      "776:\tlearn: 0.3417489\ttotal: 14.8s\tremaining: 4.24s\n",
      "777:\tlearn: 0.3413662\ttotal: 14.8s\tremaining: 4.22s\n",
      "778:\tlearn: 0.3412117\ttotal: 14.8s\tremaining: 4.21s\n",
      "779:\tlearn: 0.3409462\ttotal: 14.9s\tremaining: 4.19s\n",
      "780:\tlearn: 0.3406660\ttotal: 14.9s\tremaining: 4.17s\n",
      "781:\tlearn: 0.3404454\ttotal: 14.9s\tremaining: 4.15s\n",
      "782:\tlearn: 0.3402328\ttotal: 14.9s\tremaining: 4.13s\n",
      "783:\tlearn: 0.3398633\ttotal: 14.9s\tremaining: 4.12s\n",
      "784:\tlearn: 0.3396363\ttotal: 15s\tremaining: 4.1s\n",
      "785:\tlearn: 0.3394086\ttotal: 15s\tremaining: 4.08s\n",
      "786:\tlearn: 0.3392828\ttotal: 15s\tremaining: 4.06s\n",
      "787:\tlearn: 0.3389970\ttotal: 15s\tremaining: 4.04s\n",
      "788:\tlearn: 0.3388325\ttotal: 15s\tremaining: 4.02s\n",
      "789:\tlearn: 0.3386182\ttotal: 15s\tremaining: 4s\n",
      "790:\tlearn: 0.3382508\ttotal: 15.1s\tremaining: 3.98s\n",
      "791:\tlearn: 0.3380912\ttotal: 15.1s\tremaining: 3.96s\n",
      "792:\tlearn: 0.3376772\ttotal: 15.1s\tremaining: 3.94s\n",
      "793:\tlearn: 0.3375352\ttotal: 15.1s\tremaining: 3.92s\n",
      "794:\tlearn: 0.3373576\ttotal: 15.1s\tremaining: 3.9s\n",
      "795:\tlearn: 0.3371021\ttotal: 15.1s\tremaining: 3.88s\n",
      "796:\tlearn: 0.3369218\ttotal: 15.2s\tremaining: 3.86s\n",
      "797:\tlearn: 0.3367660\ttotal: 15.2s\tremaining: 3.84s\n",
      "798:\tlearn: 0.3364734\ttotal: 15.2s\tremaining: 3.82s\n",
      "799:\tlearn: 0.3362484\ttotal: 15.2s\tremaining: 3.8s\n",
      "800:\tlearn: 0.3359464\ttotal: 15.2s\tremaining: 3.78s\n",
      "801:\tlearn: 0.3357773\ttotal: 15.2s\tremaining: 3.76s\n",
      "802:\tlearn: 0.3356236\ttotal: 15.3s\tremaining: 3.74s\n",
      "803:\tlearn: 0.3353567\ttotal: 15.3s\tremaining: 3.72s\n",
      "804:\tlearn: 0.3349709\ttotal: 15.3s\tremaining: 3.7s\n",
      "805:\tlearn: 0.3347916\ttotal: 15.3s\tremaining: 3.69s\n",
      "806:\tlearn: 0.3344083\ttotal: 15.3s\tremaining: 3.67s\n",
      "807:\tlearn: 0.3342069\ttotal: 15.3s\tremaining: 3.65s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808:\tlearn: 0.3340264\ttotal: 15.4s\tremaining: 3.63s\n",
      "809:\tlearn: 0.3337140\ttotal: 15.4s\tremaining: 3.61s\n",
      "810:\tlearn: 0.3334481\ttotal: 15.4s\tremaining: 3.59s\n",
      "811:\tlearn: 0.3332632\ttotal: 15.4s\tremaining: 3.57s\n",
      "812:\tlearn: 0.3330371\ttotal: 15.4s\tremaining: 3.55s\n",
      "813:\tlearn: 0.3328095\ttotal: 15.5s\tremaining: 3.53s\n",
      "814:\tlearn: 0.3324775\ttotal: 15.5s\tremaining: 3.51s\n",
      "815:\tlearn: 0.3321820\ttotal: 15.5s\tremaining: 3.49s\n",
      "816:\tlearn: 0.3319058\ttotal: 15.5s\tremaining: 3.47s\n",
      "817:\tlearn: 0.3317201\ttotal: 15.5s\tremaining: 3.45s\n",
      "818:\tlearn: 0.3314862\ttotal: 15.6s\tremaining: 3.44s\n",
      "819:\tlearn: 0.3312648\ttotal: 15.6s\tremaining: 3.42s\n",
      "820:\tlearn: 0.3310345\ttotal: 15.6s\tremaining: 3.4s\n",
      "821:\tlearn: 0.3307695\ttotal: 15.6s\tremaining: 3.38s\n",
      "822:\tlearn: 0.3305784\ttotal: 15.6s\tremaining: 3.36s\n",
      "823:\tlearn: 0.3302843\ttotal: 15.7s\tremaining: 3.35s\n",
      "824:\tlearn: 0.3300227\ttotal: 15.7s\tremaining: 3.33s\n",
      "825:\tlearn: 0.3299083\ttotal: 15.7s\tremaining: 3.31s\n",
      "826:\tlearn: 0.3297421\ttotal: 15.7s\tremaining: 3.29s\n",
      "827:\tlearn: 0.3296292\ttotal: 15.7s\tremaining: 3.27s\n",
      "828:\tlearn: 0.3294711\ttotal: 15.8s\tremaining: 3.25s\n",
      "829:\tlearn: 0.3292618\ttotal: 15.8s\tremaining: 3.23s\n",
      "830:\tlearn: 0.3289442\ttotal: 15.8s\tremaining: 3.21s\n",
      "831:\tlearn: 0.3285942\ttotal: 15.8s\tremaining: 3.19s\n",
      "832:\tlearn: 0.3283506\ttotal: 15.8s\tremaining: 3.17s\n",
      "833:\tlearn: 0.3279929\ttotal: 15.8s\tremaining: 3.15s\n",
      "834:\tlearn: 0.3277414\ttotal: 15.9s\tremaining: 3.13s\n",
      "835:\tlearn: 0.3275695\ttotal: 15.9s\tremaining: 3.12s\n",
      "836:\tlearn: 0.3272779\ttotal: 15.9s\tremaining: 3.1s\n",
      "837:\tlearn: 0.3271239\ttotal: 15.9s\tremaining: 3.08s\n",
      "838:\tlearn: 0.3268391\ttotal: 15.9s\tremaining: 3.06s\n",
      "839:\tlearn: 0.3266320\ttotal: 15.9s\tremaining: 3.04s\n",
      "840:\tlearn: 0.3263344\ttotal: 16s\tremaining: 3.02s\n",
      "841:\tlearn: 0.3261564\ttotal: 16s\tremaining: 3s\n",
      "842:\tlearn: 0.3259125\ttotal: 16s\tremaining: 2.98s\n",
      "843:\tlearn: 0.3254940\ttotal: 16s\tremaining: 2.96s\n",
      "844:\tlearn: 0.3252386\ttotal: 16s\tremaining: 2.94s\n",
      "845:\tlearn: 0.3250820\ttotal: 16s\tremaining: 2.92s\n",
      "846:\tlearn: 0.3249108\ttotal: 16s\tremaining: 2.9s\n",
      "847:\tlearn: 0.3246150\ttotal: 16.1s\tremaining: 2.88s\n",
      "848:\tlearn: 0.3241912\ttotal: 16.1s\tremaining: 2.86s\n",
      "849:\tlearn: 0.3240421\ttotal: 16.1s\tremaining: 2.84s\n",
      "850:\tlearn: 0.3236917\ttotal: 16.1s\tremaining: 2.82s\n",
      "851:\tlearn: 0.3233148\ttotal: 16.1s\tremaining: 2.8s\n",
      "852:\tlearn: 0.3229835\ttotal: 16.1s\tremaining: 2.78s\n",
      "853:\tlearn: 0.3227693\ttotal: 16.1s\tremaining: 2.76s\n",
      "854:\tlearn: 0.3225397\ttotal: 16.2s\tremaining: 2.74s\n",
      "855:\tlearn: 0.3222785\ttotal: 16.2s\tremaining: 2.72s\n",
      "856:\tlearn: 0.3220841\ttotal: 16.2s\tremaining: 2.7s\n",
      "857:\tlearn: 0.3219036\ttotal: 16.2s\tremaining: 2.68s\n",
      "858:\tlearn: 0.3215944\ttotal: 16.2s\tremaining: 2.66s\n",
      "859:\tlearn: 0.3213198\ttotal: 16.2s\tremaining: 2.64s\n",
      "860:\tlearn: 0.3211715\ttotal: 16.3s\tremaining: 2.63s\n",
      "861:\tlearn: 0.3209432\ttotal: 16.3s\tremaining: 2.61s\n",
      "862:\tlearn: 0.3207798\ttotal: 16.3s\tremaining: 2.59s\n",
      "863:\tlearn: 0.3203724\ttotal: 16.3s\tremaining: 2.57s\n",
      "864:\tlearn: 0.3202202\ttotal: 16.3s\tremaining: 2.55s\n",
      "865:\tlearn: 0.3200266\ttotal: 16.4s\tremaining: 2.53s\n",
      "866:\tlearn: 0.3196128\ttotal: 16.4s\tremaining: 2.51s\n",
      "867:\tlearn: 0.3193308\ttotal: 16.4s\tremaining: 2.49s\n",
      "868:\tlearn: 0.3188492\ttotal: 16.4s\tremaining: 2.47s\n",
      "869:\tlearn: 0.3184775\ttotal: 16.4s\tremaining: 2.46s\n",
      "870:\tlearn: 0.3182246\ttotal: 16.5s\tremaining: 2.44s\n",
      "871:\tlearn: 0.3180624\ttotal: 16.5s\tremaining: 2.42s\n",
      "872:\tlearn: 0.3177209\ttotal: 16.5s\tremaining: 2.4s\n",
      "873:\tlearn: 0.3174803\ttotal: 16.5s\tremaining: 2.38s\n",
      "874:\tlearn: 0.3170565\ttotal: 16.5s\tremaining: 2.36s\n",
      "875:\tlearn: 0.3168575\ttotal: 16.5s\tremaining: 2.34s\n",
      "876:\tlearn: 0.3167197\ttotal: 16.6s\tremaining: 2.32s\n",
      "877:\tlearn: 0.3165177\ttotal: 16.6s\tremaining: 2.3s\n",
      "878:\tlearn: 0.3161675\ttotal: 16.6s\tremaining: 2.29s\n",
      "879:\tlearn: 0.3160546\ttotal: 16.6s\tremaining: 2.27s\n",
      "880:\tlearn: 0.3158690\ttotal: 16.6s\tremaining: 2.25s\n",
      "881:\tlearn: 0.3155115\ttotal: 16.7s\tremaining: 2.23s\n",
      "882:\tlearn: 0.3152518\ttotal: 16.7s\tremaining: 2.21s\n",
      "883:\tlearn: 0.3150902\ttotal: 16.7s\tremaining: 2.19s\n",
      "884:\tlearn: 0.3147378\ttotal: 16.7s\tremaining: 2.17s\n",
      "885:\tlearn: 0.3145081\ttotal: 16.7s\tremaining: 2.15s\n",
      "886:\tlearn: 0.3143381\ttotal: 16.7s\tremaining: 2.13s\n",
      "887:\tlearn: 0.3140177\ttotal: 16.8s\tremaining: 2.11s\n",
      "888:\tlearn: 0.3137757\ttotal: 16.8s\tremaining: 2.1s\n",
      "889:\tlearn: 0.3134137\ttotal: 16.8s\tremaining: 2.08s\n",
      "890:\tlearn: 0.3130981\ttotal: 16.8s\tremaining: 2.06s\n",
      "891:\tlearn: 0.3130064\ttotal: 16.8s\tremaining: 2.04s\n",
      "892:\tlearn: 0.3127875\ttotal: 16.9s\tremaining: 2.02s\n",
      "893:\tlearn: 0.3126603\ttotal: 16.9s\tremaining: 2s\n",
      "894:\tlearn: 0.3124402\ttotal: 16.9s\tremaining: 1.98s\n",
      "895:\tlearn: 0.3122123\ttotal: 16.9s\tremaining: 1.96s\n",
      "896:\tlearn: 0.3120455\ttotal: 16.9s\tremaining: 1.94s\n",
      "897:\tlearn: 0.3118024\ttotal: 16.9s\tremaining: 1.92s\n",
      "898:\tlearn: 0.3115687\ttotal: 16.9s\tremaining: 1.9s\n",
      "899:\tlearn: 0.3112827\ttotal: 17s\tremaining: 1.88s\n",
      "900:\tlearn: 0.3110942\ttotal: 17s\tremaining: 1.86s\n",
      "901:\tlearn: 0.3107888\ttotal: 17s\tremaining: 1.84s\n",
      "902:\tlearn: 0.3105953\ttotal: 17s\tremaining: 1.82s\n",
      "903:\tlearn: 0.3104062\ttotal: 17s\tremaining: 1.81s\n",
      "904:\tlearn: 0.3101082\ttotal: 17s\tremaining: 1.79s\n",
      "905:\tlearn: 0.3099119\ttotal: 17.1s\tremaining: 1.77s\n",
      "906:\tlearn: 0.3095951\ttotal: 17.1s\tremaining: 1.75s\n",
      "907:\tlearn: 0.3094850\ttotal: 17.1s\tremaining: 1.73s\n",
      "908:\tlearn: 0.3092054\ttotal: 17.1s\tremaining: 1.71s\n",
      "909:\tlearn: 0.3089214\ttotal: 17.1s\tremaining: 1.69s\n",
      "910:\tlearn: 0.3085196\ttotal: 17.1s\tremaining: 1.67s\n",
      "911:\tlearn: 0.3083641\ttotal: 17.1s\tremaining: 1.65s\n",
      "912:\tlearn: 0.3081679\ttotal: 17.1s\tremaining: 1.63s\n",
      "913:\tlearn: 0.3079290\ttotal: 17.2s\tremaining: 1.61s\n",
      "914:\tlearn: 0.3076719\ttotal: 17.2s\tremaining: 1.59s\n",
      "915:\tlearn: 0.3073525\ttotal: 17.2s\tremaining: 1.58s\n",
      "916:\tlearn: 0.3070684\ttotal: 17.2s\tremaining: 1.56s\n",
      "917:\tlearn: 0.3067712\ttotal: 17.2s\tremaining: 1.54s\n",
      "918:\tlearn: 0.3065929\ttotal: 17.2s\tremaining: 1.52s\n",
      "919:\tlearn: 0.3063760\ttotal: 17.3s\tremaining: 1.5s\n",
      "920:\tlearn: 0.3061922\ttotal: 17.3s\tremaining: 1.48s\n",
      "921:\tlearn: 0.3059131\ttotal: 17.3s\tremaining: 1.46s\n",
      "922:\tlearn: 0.3056989\ttotal: 17.3s\tremaining: 1.44s\n",
      "923:\tlearn: 0.3054833\ttotal: 17.3s\tremaining: 1.42s\n",
      "924:\tlearn: 0.3051892\ttotal: 17.3s\tremaining: 1.41s\n",
      "925:\tlearn: 0.3050243\ttotal: 17.3s\tremaining: 1.39s\n",
      "926:\tlearn: 0.3048348\ttotal: 17.4s\tremaining: 1.37s\n",
      "927:\tlearn: 0.3046488\ttotal: 17.4s\tremaining: 1.35s\n",
      "928:\tlearn: 0.3044814\ttotal: 17.4s\tremaining: 1.33s\n",
      "929:\tlearn: 0.3042264\ttotal: 17.4s\tremaining: 1.31s\n",
      "930:\tlearn: 0.3038476\ttotal: 17.4s\tremaining: 1.29s\n",
      "931:\tlearn: 0.3037554\ttotal: 17.5s\tremaining: 1.27s\n",
      "932:\tlearn: 0.3035075\ttotal: 17.5s\tremaining: 1.25s\n",
      "933:\tlearn: 0.3032762\ttotal: 17.5s\tremaining: 1.24s\n",
      "934:\tlearn: 0.3030239\ttotal: 17.5s\tremaining: 1.22s\n",
      "935:\tlearn: 0.3029429\ttotal: 17.5s\tremaining: 1.2s\n",
      "936:\tlearn: 0.3027053\ttotal: 17.5s\tremaining: 1.18s\n",
      "937:\tlearn: 0.3025052\ttotal: 17.6s\tremaining: 1.16s\n",
      "938:\tlearn: 0.3023490\ttotal: 17.6s\tremaining: 1.14s\n",
      "939:\tlearn: 0.3019937\ttotal: 17.6s\tremaining: 1.12s\n",
      "940:\tlearn: 0.3017565\ttotal: 17.6s\tremaining: 1.1s\n",
      "941:\tlearn: 0.3014945\ttotal: 17.6s\tremaining: 1.09s\n",
      "942:\tlearn: 0.3012609\ttotal: 17.7s\tremaining: 1.07s\n",
      "943:\tlearn: 0.3010099\ttotal: 17.7s\tremaining: 1.05s\n",
      "944:\tlearn: 0.3007902\ttotal: 17.7s\tremaining: 1.03s\n",
      "945:\tlearn: 0.3006296\ttotal: 17.7s\tremaining: 1.01s\n",
      "946:\tlearn: 0.3003781\ttotal: 17.8s\tremaining: 994ms\n",
      "947:\tlearn: 0.3001615\ttotal: 17.8s\tremaining: 976ms\n",
      "948:\tlearn: 0.3000209\ttotal: 17.8s\tremaining: 957ms\n",
      "949:\tlearn: 0.2996769\ttotal: 17.8s\tremaining: 938ms\n",
      "950:\tlearn: 0.2995105\ttotal: 17.8s\tremaining: 919ms\n",
      "951:\tlearn: 0.2993200\ttotal: 17.9s\tremaining: 901ms\n",
      "952:\tlearn: 0.2990935\ttotal: 17.9s\tremaining: 882ms\n",
      "953:\tlearn: 0.2988853\ttotal: 17.9s\tremaining: 863ms\n",
      "954:\tlearn: 0.2987257\ttotal: 17.9s\tremaining: 844ms\n",
      "955:\tlearn: 0.2985201\ttotal: 17.9s\tremaining: 825ms\n",
      "956:\tlearn: 0.2982879\ttotal: 17.9s\tremaining: 806ms\n",
      "957:\tlearn: 0.2980816\ttotal: 18s\tremaining: 787ms\n",
      "958:\tlearn: 0.2979264\ttotal: 18s\tremaining: 768ms\n",
      "959:\tlearn: 0.2976738\ttotal: 18s\tremaining: 749ms\n",
      "960:\tlearn: 0.2974292\ttotal: 18s\tremaining: 730ms\n",
      "961:\tlearn: 0.2972493\ttotal: 18s\tremaining: 712ms\n",
      "962:\tlearn: 0.2969381\ttotal: 18s\tremaining: 693ms\n",
      "963:\tlearn: 0.2967307\ttotal: 18.1s\tremaining: 674ms\n",
      "964:\tlearn: 0.2965545\ttotal: 18.1s\tremaining: 655ms\n",
      "965:\tlearn: 0.2961856\ttotal: 18.1s\tremaining: 637ms\n",
      "966:\tlearn: 0.2959375\ttotal: 18.1s\tremaining: 618ms\n",
      "967:\tlearn: 0.2957994\ttotal: 18.1s\tremaining: 599ms\n",
      "968:\tlearn: 0.2956924\ttotal: 18.1s\tremaining: 580ms\n",
      "969:\tlearn: 0.2954373\ttotal: 18.1s\tremaining: 561ms\n",
      "970:\tlearn: 0.2952929\ttotal: 18.2s\tremaining: 542ms\n",
      "971:\tlearn: 0.2951016\ttotal: 18.2s\tremaining: 523ms\n",
      "972:\tlearn: 0.2946346\ttotal: 18.2s\tremaining: 505ms\n",
      "973:\tlearn: 0.2944713\ttotal: 18.2s\tremaining: 486ms\n",
      "974:\tlearn: 0.2940149\ttotal: 18.2s\tremaining: 467ms\n",
      "975:\tlearn: 0.2937616\ttotal: 18.2s\tremaining: 448ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976:\tlearn: 0.2936273\ttotal: 18.2s\tremaining: 430ms\n",
      "977:\tlearn: 0.2933891\ttotal: 18.3s\tremaining: 411ms\n",
      "978:\tlearn: 0.2932187\ttotal: 18.3s\tremaining: 392ms\n",
      "979:\tlearn: 0.2930476\ttotal: 18.3s\tremaining: 373ms\n",
      "980:\tlearn: 0.2927750\ttotal: 18.3s\tremaining: 355ms\n",
      "981:\tlearn: 0.2924937\ttotal: 18.3s\tremaining: 336ms\n",
      "982:\tlearn: 0.2922248\ttotal: 18.3s\tremaining: 317ms\n",
      "983:\tlearn: 0.2920201\ttotal: 18.4s\tremaining: 298ms\n",
      "984:\tlearn: 0.2917911\ttotal: 18.4s\tremaining: 280ms\n",
      "985:\tlearn: 0.2914666\ttotal: 18.4s\tremaining: 261ms\n",
      "986:\tlearn: 0.2913760\ttotal: 18.4s\tremaining: 242ms\n",
      "987:\tlearn: 0.2910505\ttotal: 18.4s\tremaining: 224ms\n",
      "988:\tlearn: 0.2907665\ttotal: 18.4s\tremaining: 205ms\n",
      "989:\tlearn: 0.2905886\ttotal: 18.4s\tremaining: 186ms\n",
      "990:\tlearn: 0.2903488\ttotal: 18.5s\tremaining: 168ms\n",
      "991:\tlearn: 0.2899092\ttotal: 18.5s\tremaining: 149ms\n",
      "992:\tlearn: 0.2896304\ttotal: 18.5s\tremaining: 130ms\n",
      "993:\tlearn: 0.2894392\ttotal: 18.5s\tremaining: 112ms\n",
      "994:\tlearn: 0.2892600\ttotal: 18.5s\tremaining: 93.1ms\n",
      "995:\tlearn: 0.2888674\ttotal: 18.5s\tremaining: 74.4ms\n",
      "996:\tlearn: 0.2886823\ttotal: 18.6s\tremaining: 55.8ms\n",
      "997:\tlearn: 0.2885177\ttotal: 18.6s\tremaining: 37.2ms\n",
      "998:\tlearn: 0.2883787\ttotal: 18.6s\tremaining: 18.6ms\n",
      "999:\tlearn: 0.2881801\ttotal: 18.6s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Treinando cada modelo, medindo sua acurácio e guardando na lista acc_treino\n",
    "\n",
    "for model in modelos :\n",
    "    model.fit(X, target)\n",
    "    acc_treino.append(model.score(X, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4b116f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista contendo o nome de cada modelo\n",
    "\n",
    "nome_modelo = ['LogisticRegression' , 'KNeighborsClassifier' , 'SVC' , 'DecisionTreeClassifier' ,\n",
    "           'RandomForestClassifier' , 'AdaBoostClassifier' , 'GradientBoostingClassifier' ,\n",
    "           'XGBClassifier' , 'LGBMClassifier', 'CatBoostClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e9cca18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Acurácia no conjunto de treino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.637339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.736052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.675966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.804721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.937768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.954936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Modelo  Acurácia no conjunto de treino\n",
       "0          LogisticRegression                        0.637339\n",
       "1        KNeighborsClassifier                        0.736052\n",
       "2                         SVC                        0.675966\n",
       "3      DecisionTreeClassifier                        1.000000\n",
       "4      RandomForestClassifier                        1.000000\n",
       "5          AdaBoostClassifier                        0.804721\n",
       "6  GradientBoostingClassifier                        0.937768\n",
       "7               XGBClassifier                        1.000000\n",
       "8              LGBMClassifier                        1.000000\n",
       "9          CatBoostClassifier                        0.954936"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um dataframe para visualizar a acurácia de cada modelo ao fazermos previsões no conjunto de treino\n",
    "\n",
    "pd.DataFrame({'Modelo' : nome_modelo , 'Acurácia no conjunto de treino' : acc_treino})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50039164",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Podemos observar que treinamos 10 modelos distintos e 4 deles nos deram acurácia de 100% , ou seja, 4 modelos acertaram os 466 exemplos e nem precisamos otimizar hiperparâmetros. Isso é excelente ! </p>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0862ce0",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Devemos nos lembrar que a acurácia obtida quando fazemos previsões no conjunto de treino é praticamente sempre maior que a obtida em um conjunto de dados não vistos, pois um determinado modelo pode sofrer de overfitting, isto é, pode estar apenas \"indo bem\" nos dados vistos e pode não conseguir generalizar tão bem para dados não vistos pelo modelo. Isso é comum e seria como se o modelo estivesse apenas decorando os exemplos do conjunto de treino, o que pode acontecer uma vez que o dataset é pequeno. Será que os nossos modelos generalizam bem para dados não vistos ? É o que veremos na próxima seção !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b893a2",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Antes preciso ressaltar que se o objetivo for apenas medir a acurácia no conjunto de treino então qualquer um dos 4 modelos que obtém acurácia de 100% (Árvore de decisão , Random Forest, XGB e LGBM) é uma boa escolha ! Na próxima seção verificaremos se o Random Forest, XGB e LGBM generalizam bem para dados não vistos e deixaremos de fora o modelo de Árvore de Decisão, pois esse tipo de modelo costuma sofrer de overfitting (árvores muito profundas decoram os exemplos de treino, mas possuem dificuldade de generalizar)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ba635",
   "metadata": {},
   "source": [
    "## <center> 4. Avaliação da Performance do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1155cad2",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Já avaliamos a performance dos nossos modelos quando treinamos no dataset inteiro. Agora utilizaremos uma técnica chamada validação cruzada que permite treinarmos nossos modelos em diferentes partes do dataset e avaliarmos a performance na parte restante do dataset (parte que ficou de fora do treinamento). Vamos inicialmente utilizar uma validação cruzada com 5 dobras. Essa técnica nos dará uma noção melhor de como o modelo está generalizando, pois faremos diferentes treinamentos (um em cada parte do dataset) e também avaliaremos a performance em distintas dobras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5549df",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3be06b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68085106, 0.60215054, 0.67741935, 0.60215054, 0.69892473])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acurácia do Random Forest nas diferentes dobras\n",
    "\n",
    "RandomForest_acc = cross_val_score(RandomForestClassifier() , X , target , cv = 5)\n",
    "\n",
    "RandomForest_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a51c83bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6522992450240219"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acurácia média das 5 dobras\n",
    "\n",
    "np.mean(RandomForest_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d08a6",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3db9f0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:38:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:42] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:42] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:42] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.68085106, 0.64516129, 0.67741935, 0.66666667, 0.66666667])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acurácia do XGBClassifier nas diferentes dobras\n",
    "\n",
    "XGB_acc = cross_val_score(XGBClassifier(use_label_encoder = False) , X , target , cv = 5)\n",
    "\n",
    "XGB_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a67cca15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6673530084648821"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acurácia média das 5 dobras\n",
    "\n",
    "np.mean(XGB_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508a62a",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38b10a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65957447, 0.60215054, 0.6344086 , 0.62365591, 0.72043011])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acurácia do LGBMClassifier nas diferentes dobras\n",
    "\n",
    "LGBM_acc = cross_val_score(LGBMClassifier() , X , target , cv = 5)\n",
    "\n",
    "LGBM_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25a6ea2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6480439258750857"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acurácia média das 5 dobras\n",
    "\n",
    "np.mean(LGBM_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76411412",
   "metadata": {},
   "source": [
    "### Considerações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90727e0f",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Como podemos perceber a performance dos 3 modelos é bem diferente quando avaliamos em dados vistos durante o treinamento e quando avaliamos em dados não vistos. Os 3 modelos acertam todos os exemplos vistos durante o treinamento e acertam em média aproximadamente 2 de cada 3 exemplos não vistos. Bem, acertar 2 de cada 3 exemplos não vistos durante o treinamento não é um resultado ruim. Isso acontece porque o dataset é bem pequeno, seriam necessárias mais que 466 amostras para construirmos um modelo mais potente e capaz de generalizar melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c25669",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Dos 3 modelos o que gerou a acurácia mais alta foi o XGBClassifier com aproximadamente 66,74%. Vamos tentar aumentar um pouco mais a acurácia otimizando os hiperparâmetros desse modelo :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f780b8c0",
   "metadata": {},
   "source": [
    "### Otimização de Hiperparâmetros com GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f969c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma primeira grade para tentarmos otimizar o número de estimadores e a taxa de aprendizagem\n",
    "\n",
    "param_grid1 = {'n_estimators' : [300, 400, 500, 600] ,\n",
    "             'learning_rate' : [0.1 , 0.2 , 0.3 , 0.4 ,0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e73791d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = GridSearchCV(XGBClassifier(use_label_encoder = False), param_grid = param_grid1 , cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7c66810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:38:45] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:48] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:50] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:52] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:38:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:01] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:05] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:07] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:08] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:10] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:15] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:39:32] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:38] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:42] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:45] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:48] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:48] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:50] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:51] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:52] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:39:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:01] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:03] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:40:05] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:07] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:09] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:10] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:12] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:14] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:15] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:27] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:32] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:34] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:39] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:42] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:40:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:45] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         &#x27;n_estimators&#x27;: [300, 400, 500, 600]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         &#x27;n_estimators&#x27;: [300, 400, 500, 600]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, gamma=None, gpu_id=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, use_label_encoder=False,\n",
       "              validate_parameters=None, verbosity=None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, gamma=None, gpu_id=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, use_label_encoder=False,\n",
       "              validate_parameters=None, verbosity=None)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'n_estimators': [300, 400, 500, 600]})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pode levar alguns minutos...\n",
    "\n",
    "gs1.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9e7f02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6802791123312742"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observando o melhor score obtido\n",
    "\n",
    "gs1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cf02093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.5, 'n_estimators': 500}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descobrindo quais hiperparâmetros nos permitem obter o melhor score\n",
    "\n",
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91f364",
   "metadata": {},
   "source": [
    "Repare que conseguimos obter uma acurácia média de 0.6802 que é superior a 0.6674 obtido com o XGB na sua configuração padrão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a706328d",
   "metadata": {},
   "source": [
    "Será que conseguimos melhorar ainda mais a acurácia modificando o hiperparâmetro max_depth ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9ca3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma segunda grade para tentarmos otimizar o hiperparâmetro max_depth\n",
    "\n",
    "param_grid2 = {'max_depth' : range(1, 11)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49f2831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GridSearchCV(XGBClassifier(use_label_encoder = False, learning_rate = 0.5 , n_estimators = 500),\n",
    "                   param_grid = param_grid2 , cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9eb2993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:40:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:48] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:48] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:50] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:51] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:52] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:55] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:01] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:03] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:05] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:07] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:08] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:09] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:10] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:12] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:14] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:41:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:27] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:32] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:34] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.5, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=500, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={&#x27;max_depth&#x27;: range(1, 11)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.5, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=500, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={&#x27;max_depth&#x27;: range(1, 11)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, gamma=None, gpu_id=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.5, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, use_label_encoder=False,\n",
       "              validate_parameters=None, verbosity=None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, gamma=None, gpu_id=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.5, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, use_label_encoder=False,\n",
       "              validate_parameters=None, verbosity=None)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.5, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=500, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'max_depth': range(1, 11)})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eeadb84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6802791123312742"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observando o melhor score obtido\n",
    "\n",
    "gs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d684bb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descobrindo qual hiperparâmetro nos permitem obter o melhor score\n",
    "\n",
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e860b1e",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> O valor de max_depth na configuração padrão do XGBClassifier, ou seja, max_depth = 6 é quem gera o melhor score quando learning_rate = 0.5 e n_estimators = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72618f5b",
   "metadata": {},
   "source": [
    "Podemos concluir então que uma boa escolha de modelo é um XGBClassifier com os seguintes hiperparâmetros :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f14dd21",
   "metadata": {},
   "source": [
    "**n_estimators = 500**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393dad26",
   "metadata": {},
   "source": [
    "**learning_rate = 0.5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc2390",
   "metadata": {},
   "source": [
    "**max_depth = 6**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
