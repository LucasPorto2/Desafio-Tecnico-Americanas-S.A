{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a7c3b7",
   "metadata": {},
   "source": [
    "# <center> Entrega do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc626e",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> O objetivo desta seção é apresentar a função final_model que nos permite obter previsões com base em um modelo XGB treinado em todas as 466 amostras do dataset. Além disso também são apresentados alguns exemplos de como usar a função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40569144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas importações básicas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99138a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model():\n",
    "    \"\"\"Utiliza um modelo XGB treinado no dataset de 466 amostras inteiro para fazer previsões. Basta ao usuário chamar a\n",
    "    função e preencher os valores que ele desejar para feature0, feature1, ..., feature15. Após isso a função retornará\n",
    "    a previsão do modelo para o target correspondente aos valores preenchidos.\"\"\"\n",
    "    \n",
    "    # Solicitando ao usuário que entre com os valores das features\n",
    "    \n",
    "    feature0 = float(input('feature0 :'))\n",
    "    feature1 = float(input('feature1 :'))\n",
    "    feature2 = float(input('feature2 :'))\n",
    "    feature3 = float(input('feature3 :'))\n",
    "    feature4 = float(input('feature4 :'))\n",
    "    feature5 = float(input('feature5 :'))\n",
    "    feature6 = float(input('feature6 :'))\n",
    "    feature7 = float(input('feature7 :'))\n",
    "    feature8 = float(input('feature8 :'))\n",
    "    feature9 = float(input('feature9 :'))\n",
    "    feature10 = float(input('feature10 :'))\n",
    "    feature11 = float(input('feature11 :'))\n",
    "    feature12 = float(input('feature12 :'))\n",
    "    feature13 = float(input('feature13 :'))\n",
    "    feature14 = float(input('feature14 :'))\n",
    "    feature15 = float(input('feature15 :'))\n",
    "    \n",
    "    # Guardando os valore das features\n",
    "    \n",
    "    features = [[feature0, feature1, feature2, feature3, feature4, feature5, feature5, feature7, feature8, feature9,\n",
    "                feature10, feature11, feature12, feature13, feature14, feature15]]\n",
    "\n",
    "    # Lendo o arquivo\n",
    "    df = pd.read_parquet('dataset_cdjr.parquet.gzip' , engine = 'pyarrow')\n",
    "    \n",
    "    # Separando em X e target para treinar o modelo\n",
    "    \n",
    "    X = np.array(df.drop(['target'] , axis = 1))\n",
    "    target = np.array(df['target'])\n",
    "    \n",
    "    # Feature Scaling\n",
    "    SS = StandardScaler()\n",
    "    SS.fit(X)\n",
    "    X_transformada = SS.transform(X)\n",
    "    features_transformada = SS.transform(features) \n",
    "    \n",
    "    # Instanciando e treinando o modelo\n",
    "    model = XGBClassifier(n_estimators = 500 , learning_rate = 0.5 , max_depth = 6 , use_label_encoder = False)\n",
    "    model.fit(X_transformada, target)\n",
    "    \n",
    "    # Fazendo previsões\n",
    "    predictions = model.predict(features_transformada)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9c36e",
   "metadata": {},
   "source": [
    "## <center> Exemplo de como usar a função final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c0a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o conjunto de dados e transformando o mesmo em um dataframe\n",
    "\n",
    "df = pd.read_parquet('dataset_cdjr.parquet.gzip' , engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d89bc33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2</td>\n",
       "      <td>662.28</td>\n",
       "      <td>39.10</td>\n",
       "      <td>-188.55</td>\n",
       "      <td>0.246978</td>\n",
       "      <td>761</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>3.523703</td>\n",
       "      <td>167326</td>\n",
       "      <td>33441.06</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>26.850</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>94.611429</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>149.55</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79</td>\n",
       "      <td>78.93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>346.08</td>\n",
       "      <td>30.41</td>\n",
       "      <td>-102.10</td>\n",
       "      <td>2.430952</td>\n",
       "      <td>42</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>3.389618</td>\n",
       "      <td>9907</td>\n",
       "      <td>18858.77</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>25.525</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>86.520000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.84</td>\n",
       "      <td>-56.16</td>\n",
       "      <td>0.150968</td>\n",
       "      <td>372</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63544</td>\n",
       "      <td>1164.11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>87.56</td>\n",
       "      <td>-3.05</td>\n",
       "      <td>-94.50</td>\n",
       "      <td>0.412664</td>\n",
       "      <td>229</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.926561</td>\n",
       "      <td>50089</td>\n",
       "      <td>1786.26</td>\n",
       "      <td>0.049019</td>\n",
       "      <td>94.500</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>87.560000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "337     200.0         2    662.28     39.10   -188.55  0.246978       761   \n",
       "266     150.0         2      0.00    149.55     -0.45  0.150000         3   \n",
       "236      50.0         1    346.08     30.41   -102.10  2.430952        42   \n",
       "274     100.0         2      0.00     43.84    -56.16  0.150968       372   \n",
       "208      50.0         1     87.56     -3.05    -94.50  0.412664       229   \n",
       "\n",
       "     feature7  feature8  feature9  feature10  feature11  feature12  feature13  \\\n",
       "337  0.004548  3.523703    167326   33441.06   0.019804     26.850   0.009198   \n",
       "266  0.037975  0.000000        79      78.93   0.000000      0.000   0.000000   \n",
       "236  0.004239  3.389618      9907   18858.77   0.018351     25.525   0.095238   \n",
       "274  0.005854  0.000000     63544    1164.11   0.000000      0.000   0.000000   \n",
       "208  0.004572  0.926561     50089    1786.26   0.049019     94.500   0.004367   \n",
       "\n",
       "     feature14  feature15  target  \n",
       "337  94.611429          7       0  \n",
       "266   0.000000          0       1  \n",
       "236  86.520000          4       0  \n",
       "274   0.000000          0       1  \n",
       "208  87.560000          1       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observando as 5 primeiras linhas do dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e76b4b5",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Repare que a primeira linha do dataframe possui target = 0 . Vamos então chamar nossa função final_model e inserir os valores correspondentes das features para verificarmos que a saída da nossa função prevê corretamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0175753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature0 :200\n",
      "feature1 :2\n",
      "feature2 :662.28\n",
      "feature3 :39.10\n",
      "feature4 :-188.55\n",
      "feature5 :0.246978\n",
      "feature6 :761\n",
      "feature7 :0.004548\n",
      "feature8 :3.523703\n",
      "feature9 :167326\n",
      "feature10 :33441.06\n",
      "feature11 :0.019804\n",
      "feature12 :26850\n",
      "feature13 :0.009198\n",
      "feature14 :94.611429\n",
      "feature15 :7\n",
      "[07:07:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51d56c",
   "metadata": {},
   "source": [
    "Perfeito ! O nosso modelo prevê corretamente o alvo !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662a3fe",
   "metadata": {},
   "source": [
    "A segunda linha do dataframe possui target = 1 . Vamos verificar se nossa função final_model acerta novamente :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e4e8878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature0 :150\n",
      "feature1 :2\n",
      "feature2 :0\n",
      "feature3 :149.55\n",
      "feature4 :-0.45\n",
      "feature5 :0.15\n",
      "feature6 :3\n",
      "feature7 :0.037975\n",
      "feature8 :0\n",
      "feature9 :79\n",
      "feature10 :78.93\n",
      "feature11 :0\n",
      "feature12 :0\n",
      "feature13 :0\n",
      "feature14 :0\n",
      "feature15 :0\n",
      "[07:10:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a451b",
   "metadata": {},
   "source": [
    "Acertamos novamente !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412f5f9",
   "metadata": {},
   "source": [
    "## <center> Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb86f8",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Conforme mostrado no notebook Desafio Técnico - Cientista de Dados - Americanas S.A..ipynb presente no repositório um modelo XGB treinado em todo o dataset de 466 amostras possui acurácia de 100% quando são feitas previsões no próprio conjunto de treino. Isso quer dizer que o modelo acerta o alvo para todas as 466 amostras !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feec1aa",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Portanto, não é novidade nossa função final_model prever corretamente as duas primeiras linhas do dataframe. Em particular, ela prevê corretamente todas as linhas do dataframe, ou seja, todas as amostras !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a340b",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Por fim, concluo dizendo que para dados não vistos, isto é, para qualquer outra amostra diferente das 466 do conjunto de treino a história é um pouco diferente ! Segundo nossa validação cruzada é esperado que tenhamos uma probabilidade de acerto de aproximadamente 68% ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
